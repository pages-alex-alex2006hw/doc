\documentclass{myproc}
\usepackage{theorem,mydef,latexsym,amssymb}
\usepackage[all]{xy}
\def\hm{{\sf{}Halting$_{\mbox{\scriptsize{}TM}}$}}
\def\am{{\sf{}Accepts$_{\mbox{\scriptsize{}TM}}$}}
\def\etm{{\sf{}AcceptNothing$_{\mbox{\scriptsize{}TM}}$}}
\begin{document}
\small
\title{\large\bf{}Notes on Theory of Computation}
%\author{\normalsize{}¡§ √∂¡÷}
\date{}
\maketitle
\small
\section{Elementary Language Theory}
\subsection{Languages and Grammars}
\bit
\w {\em{}Language\/} $L$ is a set of finite strings over some finite alphabet
	$\Sigma$.
\w A {\em{}grammar\/} is a $4$-tuple $G = (N, T, P, S)$ where
	\ben	
	\w [(a)] $N$ is a finite set of {\bf{}nonterminal symbols}
		(a.k.a. {\em{}variables\/} or {\em{}syntactic categories\/}).
	\w [(b)] $T$ is a finite set of {\bf{}terminal symbols}.
		disjoint from $N$.
	\w [(c)] $P$ is a finite subset of 
		\[ (N \cup T)^*N(N \cup T)^* \times (N \cup T)^*, \]
		An element $(\alpha, \beta) \in P$ will be written 
		$\alpha \rightarrow \beta$ and called a {\bf{}production}.
	\w [(d)] $S$ is a distinguished symbol in $N$ called the {\bf{}start
		symbol} (a.k.a. {\em{}sentence symbol\/}).
	\een
\w A grammar defines a language in a recursive manner.
\w A {\bf{}sentential form} of a grammar $G = (N, T, P, S)$ is defined
	as follows:
	\ben
	\w [(a)] $S$ is a sentential form.
	\w [(b)] If $\alpha\beta\gamma$ is a sentential form and
		$\beta \rightarrow \delta \in P$, then
		$\alpha\delta\gamma$ is also a sentential form.
	\een
\w A sentential form with no nonterminal symbols is called a
	{\bf{}sentence} generated by $G$.
\w The {\bf{}language generated by a grammar} $G$, denoted $L(G)$, is
	the set of sentences generated by $G$.
\w We define a relation $\Ra_G$ (read as {\bf{}directly derives})
	as follows:
	If $\alpha\beta\gamma$ is a string in $(N \cup T)^*$
	and $\beta \rightarrow \delta$ is a production in $P$, then
	$\alpha\beta\gamma \Rightarrow_G \alpha\delta\gamma$.
	\bit
	\w $\Ra^+_G$ is the transitive closure of $\Ra_G$.
	\w $\Ra^*_G$ is the reflexive and transitive closure of $\Ra_G$.
	\w $\Ra^k_G$ is the $k$-fold product of $\Ra_G$.
	\w $\Ra_G$ is usually written as $\Ra$ when $G$ is clear from
		the context.
	\eit
\w $L(G) = \{w : w \in T^* \mbox{\ and\ } S \Rightarrow^* w\}$.
\eit

\subsection{Restricted grammars}
\bit
\w Let $G = (N, T, P, S)$ be a grammar. $G$ is said to be
	\ben
	\w {\bf{}right-linear} if each production in $P$ is of the form
		$A \rightarrow xB$ or $A \rightarrow x$ where
		$A, B \in N$ and $x \in T^*$.
	\w {\bf{}context-free} if each production in $P$ is of the form
		$A \rightarrow \alpha$, where
		$A \in N$ and $\alpha \in (N \cup T)^*)$.\
	\w {\bf{}context-sensitive} if each production in $P$ is of the
		form $\alpha \rightarrow \beta$, where $|\alpha| \le
		|\beta|$.
	\w {\bf{}unrestricted} if $G$ has no restrictions given above.
	\een
\eit


\section{Finite Automata and Regular Expressions}
\subsection{Deterministic Finite Automata}
\begin{itemize}
\item We denote a {\bf{}$($deterministic$)$ finite automaton} by a 
	5-tuple $M = (Q, \Sigma, \delta, q_0, F)$, where $Q$ is a finite
	set of {\em{}states\/}, $\Sigma$ is a finite {\em{}input alphabet\/},
	$q_0 \in Q$ is the {\em{}initial state\/}, $F \subseteq Q$ is the
	set of {\em{}final states\/}, and $\delta$ is the {\em{}transition
	function\/} mapping $Q\times\Sigma$ to $Q$.
	\begin{itemize}
	\item $\delta: Q \times \Sigma \rightarrow Q$: in \cite{HU79},
		$\delta$ is defined as a {\bf{}total function}
	\item $|F| \ge 1$
	\end{itemize}
\item Extending $\delta$ to $\hat\delta: Q\times\Sigma^* \rightarrow Q$
	\begin{enumerate}
	\item [(a)] $\hat\delta(q, \epsilon) = q$, 
	\item [(b)] $\hat\delta(q, wa) = \delta(\hat\delta(q, w), a)$
	\end{enumerate}
\item A string $x$ is said to be {\bf{}accepted} by a finite automaton
	$M = (Q, \Sigma, \delta, q_0, F)$ if 
	$\delta(q_0, x) = p$ for some $p \in F$.
\item The {\bf{}language accepted\footnote{In \cite{Sipser96}, to avoid
	the confusion incurred by the fact that both strings and languages
	are `accepted' by machines, Sipser suggested that `{\bf{}recognized}'
	should be used instead of `accepted' in this case.} 
	by $M$}, designated $L(M)$, is the
	set $\{x: \delta(q_0, x) \in F\}$.
\item A langauge is a {\bf{}regular set} (or just {\bf{}regular}) 
	if it is the set accepted by some finite automaton.
\end{itemize}
\subsection{Nondeterministic Finite Automata}
\begin{itemize}
\item A {\bf{}nondeterministic finite automaton} is a $5$-tuple
	$(Q, \Sigma, \delta, q_0, F)$ where 
	$\delta$ is a map from $Q \times \Sigma$ to $2^Q$.
	\begin{itemize}
	\item Note that $\delta(q, a)$ can be $\emptyset$ and $\delta$ is
		a {\em{}total function\/}.
	\end{itemize}
\item Extending $\delta$ to $\hat\delta: Q\times\Sigma^* \rightarrow 2^Q$
	\begin{enumerate}
	\item [(a)] $\hat\delta(q, \epsilon) = q$, 
	\item [(b)] $\hat\delta(q, wa) =
		\{p: \mbox{for some state $r \in \hat\delta(q, w)$, 
		$p \in \delta(r, a)$}\}$, i.e.
		\[ \hat\delta(q, wa) = \bigcup_{r \in \hat\delta(q, w)} \delta(r, a)\]
	\end{enumerate}
\item Let's use $\delta$ in place of $\hat\delta$ for convenience.
\item Extending $\delta$ to $\delta: 2^Q\times\Sigma^* \rightarrow 2^Q$
	\[\delta(P, w) = \bigcup_{q \in P} \delta(q, w).\]
\item $L(M)$, the {\bf{}language accepted by} an NFA
	is 
	\[\{w: \delta(q_0, w) \mbox{\ contains a state in $F$}\},\] 
	i.e.,
	\[ \{w: \delta(q_0, w) \cap F \ne \emptyset\} \]
\item ({\bf{}Equivalence of DFA's and NFA's})
	Let $L$ be a set accepted by a nondeterministic
		finite automaton. Then there exists a deterministic finite automaton
		that accepts $L$.
	\begin{itemize}
	\item $M = (Q, \Sigma, \delta, q_0, F)$: an NFA accepting $L$.
	\item $M' = (Q', \Sigma, \delta', q_0', F')$: a DFA accepting $L$.
		\begin{itemize}
		\item $Q' = 2^Q$
		\item $\delta'([q_1, \cdots, q_k], a) = [p_1, \cdots, p_l]$ iff
			$\delta(\{q_1, \cdots, q_k\}, a) = \{p_1, \cdots, p_l\}$
		\item $q_0' = [q_0]$
		\item $F' = [q \in Q': (\exists{f \in F})[f \in q]]$
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsection{Nondeterministic Finite Automata with $\epsilon$-moves}
\begin{itemize}
\item A {\bf{}nondeterministic finite automaton with $\epsilon$-moves}
	is a quintuple $(Q, \Sigma, \delta, q_0, F)$ with all components
	as before, but $\delta$ maps $Q \times (\Sigma \cup \{\epsilon\})$
	to $2^Q$.
\w $\epsilon$-CLOSURE$(q)$ is the set of states reachable from $q$
	using $\epsilon$-transitions only.
\w Extending $\delta$ to $\hat\delta: Q\times\Sigma^* \ra 2^Q$
	\bit
	\w [(a)] $\hat\delta(q, \epsilon) = \epsilon\mbox{-CLOSURE}(q)$
	\w [(b)] $\hat\delta(q, wa) = \epsilon\mbox{-CLOSURE}(P)$, where
		$P = \{p: (\exists{}r\in\hat\delta(q, w))[p \in \delta(r, a)]\}$, 
			i.e.,
			\[ \hat\delta(q, wa) = 
			\epsilon\mbox{-CLOSURE}(\delta(\hat\delta(q, w), a))\]
	\eit
\w Extending $\delta$ and $\hat\delta$ 
	to $\delta,\hat\delta: 2^Q\times\Sigma^* \ra 2^Q$
	\bit
	\w [(a)] $\delta(R, a) = \bigcup_{q \in R}\delta(q, a)$
	\w [(b)] $\delta(R, w) = \bigcup_{q \in R}\hat\delta(q, a)$
	\eit
\w Note that {\em\bfseries{}$\hat\delta(q, a)$ is not necessarily equal to 
	$\delta(q, a)$\/} because of the $\epsilon$-transitions.
\w $L(M)$ , the {\em{}language accepted by a nondeterministic finite automaton
	with $\epsilon$-moves\/} is defined to be 
	$\{w: \hat\delta(q_0, w) \cap F \ne \emptyset\}$.
\w ({\bf{}Equivalence of NFA's with and without $\epsilon$-moves})
	If $L$ is accepted by an NFA with $\epsilon$-transitions, 
		then $L$ is accepted by an NFA without $\epsilon$-transitions.
	\bit
	\w $M = (Q, \Sigma, \delta, q_0, F)$: an NFA with $\epsilon$-moves
	\w $M' = (Q', \Sigma, \delta', q_0', F')$: an NFA without $\epsilon$-moves
		\bit
		\w $Q' = Q$
		\w $\delta'(q, a) = \hat\delta(q, a)$
		\w $q_0' = q_0$
		\w $F' = \left\{ \begin{array}{ll}
			F \cup \{q_0\} & \mbox{if $\epsilon$-CLOSURE($q_0$) contains
				a state of $F$,} \\
			F & \mbox{otherwise}
			\end{array}\right.$
		\eit
	\eit
\end{itemize}

\subsection{Regular Expressions}
\begin{itemize}
\w $RS$ is defined
			to be $\{xy : x \in R \mbox{\ and\ } y \in S\}$, 
			$R^* = \bigcup_{i = 0}^\infty{R^i}$
\w $R^0 = \{\epsilon\}$, \ $R^i = RR^{i-1}$ $(i \ge 1)$
\item Given an alphabet $\Sigma$, 
	{\bf{}regular expressions over $\Sigma$} is 
	defined recursively as follows:
	\begin{enumerate}
	\item [(a)] $\emptyset$ is a regular expression, and 
		$L(\emptyset) = [\![\emptyset]\!] = \emptyset$\footnote{In the
		statement $L(\emptyset) = \emptyset$, note that the first
		$\emptyset$ is just a ``symbol'' while the second one is the 
		empty set.}
	\item [(b)] $\epsilon$ is a regular expression, and $L(\epsilon) = 
		\{\epsilon\}$
	\item [(c)] $a \in \Sigma$ is a regular expression, and 
		$L(a) = \{a\}$
	\item [(d)] If $r, s$ are  regular expressions 
		denoting $R$ and $S$, respectively, then $r+s, rs, r^*$ are 
		regular expressions, and $L(r+s) = R \cup S$, 
		$L(rs) = RS$, $L(r^*) = R^*$
	\end{enumerate}
\w Note that $r\emptyset = \emptyset{r} = \emptyset$ 
	and $\emptyset^* = \{\epsilon\}$.
\w ({\bf{}Equivalence of regular expressions and NFA's 
	with $\epsilon$-transitions})
	Let $r$ be a regular expression. Then there exists an NFA with
	$\epsilon$-transitions that accepts $L(r)$.
	\bit
	\w Use {\em{}Thompson's construction}
	\eit
\w ({\bf{}Equivalence of DFA's and regular expressions}) 
	If $L$ is accepted by the DFA then $L$ is denoted by a regular
	expression.
	\bit
	\w $M = (\{q_1, \cdots, q_n\}, \Sigma, \delta, q_1, F)$
	\w $R^k_{ij}$: the set of all strings $x$ s.t. $\delta(q_i, x) = q_j$,
		and if $\delta(q_i, y) = q_l$, for any
			$y$ that is a prefix of $x$, other than $x$ or 
			$\epsilon$,
			then $l \le k$; that is, 
			{\sl\bfseries{}$R^k_{ij}$ is the
			set of strings that take the finite automaton from 
			state
			$q_i$ to state $q_j$ without going through any state
			numbered higher than $k$}
	\w We can define $R^k_{ij}$ recursively:
		\begin{eqnarray*}
		R^k_{ij} & = & R^{k-1}_{ik}(R^{k-1}_{kk})^*R_{kj}^{k-1} 
			\cup R_{ij}^{k-1},\\
		R^0_{ij} & = & 
			\left\{\begin{array}{ll}
			\{a: \delta(q_i, a) = q_j\} & i \ne j\\
			\{a: \delta(q_i, a) = q_j\} \cup \{\epsilon\} & i = j\\
			\end{array}\right.
		\end{eqnarray*}
	\w Now what's left is to show that for each $i, j, k$, there exists
		a regular expression denoting the language $R^k_{ij}$, which
		can be proved using induction.
	\w To finish the proof, we have only to observe that
		\[ L(M) = \bigcup_{q_j \in F} R^n_{1j} \]
	\eit
\w The proof of equivalence of DFA, NFA, $\epsilon$-NFA, and regex was
	carried out according to the following scheme:
	\[\xymatrix@-1.0pc{
	& \mbox{NFA} \ar@/_3ex/[ld] & \\
	\mbox{DFA} \ar@/_3ex/[rd] & & \mbox{$\epsilon$-NFA} 
			\ar@/_3ex/[ul] \\
	& \mbox{Regex} \ar@/_3ex/[ru] &
	}\]
\end{itemize}

\subsection{Two-way Finite Automata}
\bit
\w NFA: adds {\em{}nondeterminism\/} to the model; allows
	{\em{}many ``copies'' of the control unit to exist and scan the tape
		simulataneously\/}
\w NFA with $\epsilon$-moves: allows {\em{}change of state without reading the
	input and moving the head\/}
\w Two-way finite automata (2DFA) : allows the tape head to move left as well
\w A {\bf{}two-way deterministic finite automaton} (2DFA) is a quintuple
	$M = (Q, \Sigma, \delta, q_0, F)$ where $Q, \Sigma, q_0, F$ are as
	before, and $\delta$ is a map from $Q \times \Sigma$ to
	$Q \times \{\mbox{L, R}\}$.
\w An {\bf{}instantaneous description} (ID) of a 2DFA is a string
	in $\Sigma^*Q\Sigma^*$.
	\bit
	\w Unlike DFA's, just extending $\delta$ to `$\hat\delta$' is not enough to
		describe the behavior of 2DFA. 
	\w ID describes the {\em{}input string, current state\/}, and the 
		{\em{}current position of the tape head\/}.
	\w $\vdash_M$ or $\vdash$ as a transition relation on the set of ID's
		\ben
		\w [(a)] $a_1\cdots{}a_{i-1}q a_i\cdots{a_n}$ $\vdash$
			$a_1\cdots{}a_ip a_{i+1}\cdots{a_n}$ whenenver
			$\delta(q, a_i) = (p, \mbox{R})$
		\w [(b)] $a_1\cdots{}a_{i-1}q a_i\cdots{a_n}$ $\vdash$
			$a_1\cdots{}a_{i-2}p a_{i-1}\cdots{a_n}$ whenenver
			$\delta(q, a_i) = (p, \mbox{L})$ and $i > 1$
		\een
	\eit
\w $L(M) = \{w: q_0w \vdash^* wp \mbox{\ for some $p \in F$}\}$
\w 2DFA accepts only regular sets.
\eit

\subsection{Finite Automata with Output}
\bit
\w Two finite automata with output
	\bit
	\w {\em{}Moore machine} associates output with {\em{}states\/}.
	\w {\em{}Mealy machine} associates output with {\em{}transitions\/}.
	\eit
\w A {\bf{}Moore machine} is a $6$-tuple $(Q, \Sigma, \Delta, 
	\delta, \lambda, q_0)$, where $Q, \Sigma, \delta, q_0$ are as in the DFA
	and $\Delta$ is the {\em{}output alphabet\/} and $\lambda$ is the
	{\em{}output function\/}.
	\bit
	\w $\lambda: Q \rightarrow \Delta$ associates each state with output.
	\eit
\w A {\bf{}Mealy machine} is a $6$-tuple $(Q, \Sigma, \Delta, 
	\delta, \lambda, q_0)$, where $Q, \Sigma, \Delta, \delta, q_0$ are as 
	in the Moore machine and $\lambda$ is the {\em{}output function\/}.
	\bit
	\w $\lambda: Q \times \Sigma \rightarrow \Delta$ 
		associates each transition with output.
	\eit
\w If we may neglect the response of a Moore machine to input
	$\epsilon$ then Mealy machine $M_1$ and Moore machine $M_2$
	are {\bf{}equivalent} if for all inputs $w$, 
	$bT_{M_1}(w) = T_{M_2}(w)$, where $b$ is the output of $M_2$
	for its initial state\footnote{$T_M(w)$ is the output of $M$ on $w$.}.
\eit



\section{Properties of Regular Sets}
\subsection{The Pumping Lemma for Regular Sets}
\bit
\w ({\bf{}Pumping Lemma}) {\em{}Let $L$ be a regular set. Then there is
	a constant $n$ s.t. if $z$ is any word in $L$, and $|z| \ge n$,
	we may write $z = uvw$ in such a way that
	$|uv| \le n$, $|v| \ge 1$, and for all $i \ge 0$, 
	$uv^iw$ is in $L$. Furthermore, $n$ is no greater than
	the number of states of the smallest FA accepting $L$.}
\w The pumping lemma means that given any sufficiently long string
	accepted by an FA, we can find a substring near the beginning
	of the string that may be ``pumped'', i.e. repeated as many times
	as we like, and the resulting string will be accepted by the FA.
\w {\bf{}Using pumping lemma to prove the nonregularities of languages}
	\ben
	\w Select the language $L$ you wish to prove nonregular.
	\w The ``adversary'' picks $n$, the constant mentioned in the
		pumping lemma.
	\w Select a string $z \in L$. The choice may depend implicitly
		on the value of $n$.
	\w The adversary breaks $z$ into $u, v$, and $w$, subject to 
		the constraints that $|uv| \le n$ and $|v| \ge 1$.
	\w You achieve a contradiction to the pumping lemma by
		showing, for any $u, v$, and $w$ determined by
		the adversary, that there exists an $i$ for which
		$uv^iw$ is not in $L$. It may then be concluded that
		$L$ is not regular. Selection of $i$ may depend on
		$n, u, v$, and $w$.
	\een
\w {\em{}Example\/}. The set $L = \{0^n1^n: i \mbox{\ is an integer and\ }
	i \ge 1\}$ is not regular.
	\ben
	\w Assume that $L$ is regular and the pumping lemma holds for $L$.
	\w Let $n$ be the {\bf{}pumping length}.
	\w Let $z = 0^p1^p$.
	\w By the pumping lemma $z = 0^p1^p = uvw$, where $1 \leq |v| \le n$
		and $uv^iw \in L$ for all $i$.
	\w We consider three cases:
		\bit
		\w The string $v$ consists only of $0$s; 
			then $uv^2w$ has more $0$s than $1$s.
		\w The string $v$ consists only of $1$s
			then $uv^2w$ has more $1$s than $0$s.
		\w The string $v$ consists of $0$s and $1$s; then 
			$uv^w$ may have some $1$s before $0$s.
		\eit
	\w $L$ is not regular.
	\een
\w {\em{}Example\/}. The set $L = \{0^{i^2}: i \mbox{\ is an integer and\ }
	i \ge 1\}$ is not regular.
	\ben
	\w Assume that $L$ is regular and the pumping lemma holds for $L$.
	\w Let $n$ be the integer in the pumping lemma.
	\w Let $z = 0^{n^2}$.
	\w By the pumping lemma $0^{n^2} = uvw$, where
		$1 \leq |v| \le n$ and $uv^iw$ is in $L$ for all $i$.
	\w In particular, let $i = 2$. However, 
		\[ n^2 < |uv^2w| \le n^2 + n < (n+1)^2 \]
		since $|v| \ge 1$.
		That is, the length of $uv^2w$ lies properly between $n^2$
		and $(n+1)^2$, and thus is not a perfect square.
	\w $L$ is not regular.
	\een
\eit
\subsection{Examples of Nonregular Sets}
\bit
\w The following languages are {\em{}nonregular\/} sets.
	\ben
	\w $N_1 = \{0^n1^n: n \ge 0\}$
	\w $N_2 = \{0^{2^n}: n \ge 1\}$
	\w $N_3 = \{0^{n^2}: n \ge 1\}$
	\w $N_4$: the set of strings of $0$'s and $1$'s, beginning with $1$,
		whose value treated as a binary number is a prime
	\w $N_5$: the set of strings with an equal number of $0$'s and $1$'s
	\w $N_6 = \{0^i1^j: i > j\}$
	\w $N_7 = ADD = \{x\mbox{\tt{}=}y\mbox{\tt{}+}z:$ 
		$x, y, z$ are binaries,
		and $x$ is the sum of $y$ and $z$$\}$
	\w $N_8 = \{0^n0^m0^{n+m}: n, m \ge 1\}$
	\een
\w The following languages are {\em{}regular\/} sets 
	while they may not seem to be.
	\ben
	\w $R_1$: the set of strings with an equal number of occurrences
		of $01$ and $10$ as substrings
	\w $R_2  = A^R = \{w^R: w \in A\}$ for some {\em{}regular\/} set $A$;
		$w^R$ is the {\em{}reverse string\/} of $w$
	\een
\eit

\subsection{Closure Properties of Regular Sets}
\bit
\w If a class of languages is closed under a particular
	{\em{}operation\/}, we call that fact a {\bf{}closure property}
	of the {\em{}class of languages\/}.
\w The regular sets are closed under {\bf{}union}, {\bf{}concatenation} and
	{\bf{}Kleene closure} operations.
\w The class of regular sets is closed under {\bf{}complementation}.
	That is, if $L$ is a regular set and $L \subseteq \Sigma^*$,
	then $\overline{L} = \Sigma^* - L$ is a regular set.
	\bit
	\w To accept $\overline{L}$, complement the final states of 
		$M = (Q, \Sigma, \delta, q_0, F)$, where $M$ is 
		the NFA that accepts $L$.
	\w $M^c = (Q, \Sigma, \delta, q_0, Q\setminus F)$ accepts $\overline{L}$.
	\eit
\w The regular sets are closed under {\bf{}intersection}.
	\bit
	\w Note that $L_1 \cap L_2 = \overline{\overline{L_1} 
		\cup \overline{L_2}}$.
	\eit
\w A {\bf{}substitution} $f$ is a mapping of an alphabet $\Sigma$
	onto subsets of $\Delta^*$, for some alphabet $\Delta$.
	\bit
	\w $f$ associates a {\em regular \bfseries{}language\/} 
		with each symbol of $\Sigma$.
	\eit
\w The class of regular sets are closed under substitution.
\w A {\bf{}homomorphism} $h$ is a substitution s.t.
	$h(a)$ contains a single string for each $a$.
	\bit
	\w We generally take $h(a)$ to be the string itself rather than
		the set containing that string.
	\w The {\bf{}inverse homomorphic image} of a language $L$ is 
		\[ h^{-1}(L) = \{x: h(x) \in L\}. \]
	\w For a srting $w$, $h^{-1}(w) = \{x: h(x) = w\}$.
	\eit
\w The class of regular sets is closed under homomorphism and 
	inverse homomorphism.
\w A {\bf{}quotient} of languages $L_1$ and $L_2$, written
	$L_1 / L_2$, is defined to be
		\[ \{x: \mbox{\ there exists $y \in L_2$ s.t. $xy \in L_1$}\}.\]
\w The class of regular sets is closed under quotient wit
	arbitrary sets.
\eit
\subsection{Decision Algorithms for Regular Sets}
\bit
\w Interesting questions on regular sets:
	\ben
	\w Is a given language empty, finite, or infinite?
	\w Is one regular set equivalent to another?
	\een
\w ({\bf{}Emptiness, finiteness, and infiniteness})
	The set of sentences accepted by a finite automaton $M$ with
	$n$ states is:
	\ben
	\w [(a)] {\em{}nonempty\/}
		if and only if the finite automaton accepts a
		sentence of length less than $n$.
	\w [(b)] {\em{}infinite\/}
		if and only if the automaton accepts some 
		sentence of length $l$, where $n \le l < 2n$.
	\een
\w Emptiness, finiteness, and infiniteness can be checked 
	more effciently using {\em{}reachability tests\/} and
	{\em{}cycle tests\/}.
\w There is an algorithm to determine if two finite automata, $M_1$
	and $M_2$, 
	are equivalent (i.e., if they accept the same language).
	\bit
	\w Let $L(M_1) = L_1$ and $L(M_2) = L_2$.
	\w By the closure properties of regular sets, 
		$(L_1 \cap \overline{L_2}) \cup (L_2 \cap 
		\overline{L_1})$ is regular and accepted by a finite 
		automaton $M_3$.
	\w $M_3$ accepts a word iff $L_1 \ne L_2$.
	\w Since regular sets are closed under complementation
		there's an algorithm to determine if $L_1 = L_2$.
	\eit
\eit
\subsection{The Myhill-Nerode Theorem and Minimization of 
	Finite Automata}
\bit
\w An equivalence relation $R$ s.t. $xRy$ implies $xzRyz$
	is said to be {\bf{}right invariant} (with respect to
	concatenation).
\w ({\bf{}The Myhill-Nerode Theorem}) The following
	three statements are equivalent:
	\ben
	\w [(a)] The set $L \subseteq \Sigma^*$ is accepted by 
		some finite automaton.
	\w [(b)] $L$ is the union of some of the equivalence
		classes of a right invariant equivalent relation
			of finite index.
	\w [(c)] Let equivalent relation $R_L$ be defined by:
		$xR_Ly$ iff for all $z \in \Sigma^*$, 
		$xz \in L$ eactly when $yz \in L$. Then
		$R_L$ is of finite index.
	\een
\w Proving the Myhill-Nerode Theorem 
	\bit
	\w To prove (c) $\Rightarrow$ (a), we construct a DFA
		$M' = (Q', \Sigma, \delta', q_0', F')$, where
		\bit
		\w $Q'$: the finite set of equivalence classes of $R_L$;
		\w $\delta'([x]_{R_L}, a) = [xa]_{R_L}$;
		\w $q_0' = [\epsilon]$;
		\w $F' = \{[x]_{R_L}: x \in L\}$;
		\eit
	\eit
\eit

\section{Context-Free Grammars}
\subsection{Context-Free Grammars}
\bit
\w A {\bf{}context-free grammar} (or CFG) is denoted by
	$G = (V, T, P, S)$, where $V$ and $T$ are finite sets
	of {\bf{}variables} and {\bf{}terminals}
	\bit
	\w $V$ and $T$ are disjoint.
	\w $P$ is a finite of set of {\bf{}productions}; a production
		is of the form $A \rightarrow \alpha$ where $A$ is a
		vaariable and $\alpha \in (V \cup T)^*$.
	\w $S$ is a special variable called the {\bf{}start symbol}.
	\eit
\w If $A \rightarrow \beta$ is a production of $P$ and $\alpha, \gamma$
	are any strings in $(V \cup T)^*$, then
	$\alpha{A}\gamma \Rightarrow \alpha\beta\gamma$.
	\bit
	\w We say that $\alpha{A}\gamma$ {\bf{}directly derives}
		$\alpha\beta\gamma$.
	\eit
\w $\stackrel{*}{\Rightarrow}$ is the reflexive, transitive closure
	of $\Rightarrow$.
\w A string of terminals and variables $\alpha$ is called a 
	{\bf{}sentential form} if $S \stackrel{*}{\Ra} \alpha$.
\w The {\bf{}language generated by} $G$, $L(G)$, 
	is $\{w: w \in T^* \mbox{\ and\ } S \stackrel{*}{\Ra} w\}$.
\w We call $L$ a {\bf{}context-free language} (CFL) if it is
	$L(G)$ for some CFG $G$.
\w We define grammars $G_1$ and $G_2$ to be {\bf{}equivalent}
	if $L(G_1) = L(G_2)$.
\eit

\subsection{Derivation Trees}
\bit
\w Let $G = (V, T, P, S)$ be a CFG. A tree is a {\bf{}derivation
	tree} (or {\bf{}parse tree}) if 
	\ben
	\w [(a)] Every vertex has a {\em{}label\/}, which is a symbol
		of $V \cup T \cup \{\epsilon\}$.
	\w [(b)] The label of the root is $S$.
	\w [(c)] If a vertex is interior and has label $A$, then 
		$A$ must be in $V$.
	\w [(d)] If a vertex $n$ has label $A$ and vertices $n_1, \cdots, 
		n_k$ are the children of $n$, in order from the left, with
		labels $X_1, \cdots, X_k$, respectively, then
			\[ A \rightarrow X_1\cdots{X_k} \]
			must be a production in $P$.
	\w [(e)] If a vertex $n$ has label $\epsilon$, then $n$ is a 
		leaf and is the only child of its father.
	\een
\w If we read the leaves from left to right, we have a sentential
	form. We call this string the {\bf{}yield} of the derivation tree.
\w Let $G = (V, T, P, S)$ be a context-free grammar. Then 
	$S \stackrel{*}{\Ra} \alpha$ if and only if there is a derivation
	tree in grammar $G$ with yield $\alpha$.
\w {\bf{}Leftmost and rightmost derivation}
	\bit
	\w If at each step in a derivation a production is applied to
		the {\em{}leftmost\/} variable, then the derivation is
		said to be {\bf{}leftmost}. (Rightmost derivation
			is defined similarly.)
	\w If $w \in L(G)$ for some CFG $G$, then $w$ has {\em{}at least}
		one parse tree.
	\w For a particular parse tree, {\em{}exactly one\/} leftmost
		derivation and {\em{}exactly one\/} derivation is associated 
		with the tree.
	\w A context-free grammar $G$ s.t. some word has more than two
		parse trees is said to be {\bf{}ambiguous}.
	\w A context-free language for which every CFG is ambiguous
		is said to be {\bf{}inherently ambiguous}.
	\eit
\eit

\subsection{Simplifications of Context-Free Grammars}
\bit
\w If $L$ is a nonempty context-free grammar, then it can be also
	generated by a context-free grammar $G$ s.t.
	\ben
	\w [(a)] each variable and each terminal of $G$ appears in the
		derivation of some word in $L$ and
	\w [(b)] There are no productions of the form $A \rightarrow B$
		where $A$ and $B$ are variables.
	\een
\w If $\epsilon \not\in L$, there need be no productions of the
	form $A \rightarrow \epsilon$.
\w We can require that every production of $G$ be of one of the
	forms $A \rightarrow BC$ and $A \rightarrow a$, where
	$A, B, C$ are variables and $a$ is a terminal (Chomsky normal form).
\w We can make every production of $G$ of the form $A \rightarrow a\alpha$
	where $\alpha$ is a string of (maybe empty) variables 
	(Greibach normal form). 
\w {\bf{}Useless symbols}
	\bit
	\w A symbol $X$ is {\bf{}useful} if there is a derivation
		$S \stackrel{*}{\Ra} \alpha{X}\beta \stackrel{*}{\Ra}
		w$ for some $\alpha, \beta$ and $w \in T^*$.
	\w Given a CFG $G = (V, T, P, S)$ with $L(G) \ne \emptyset$,
		we can effectivly find an equivalent CFG $G' = (V', T, P', S)$
		s.t. for each $A \in V'$ there is some $w \in T*$ for 
		which $A \stackrel{*}{\Ra} w$.
	\w Given a CFG $G = (V, T, P, S)$ with $L(G) \ne \emptyset$,
		we can effectivly find an equivalent CFG $G' = (V', T', P', S)$
		s.t. for each $X \in V' \cup T'$ there exist $\alpha, \beta
		\in (V' \cup T')^*$ for
		which $S \stackrel{*}{\Ra} \alpha{X}\beta$.
	\w Every nonempty CFL is generated by a CFG with no
		useless symbols.
	\eit
\w {\bf{}$\epsilon$-productions}
	\bit
	\w We can eliminate productions of the form 
		$A \rightarrow \alpha$, which we call 
		{\bf{}$\epsilon$-productions}.
	\w A variable $A$ is {\bf{}nullable} if there a derivation 
		$A \stackrel{*}{\Ra} \epsilon$.
	\w If $L = L(G)$ for some CFG $G = (V, T, P, S)$, then
		$L - \{\epsilon\}$ is $L(G')$ for a CFG $G' = (V, T, P', S)$ 
		with no useless symbols or $\epsilon$-productions.
		\bit
		\w To construct $P'$, if $A \rightarrow X_1\cdots{X_k} \in P$,
			then add all productions 
			$A \rightarrow \alpha_1\cdots{\alpha_k}$ to $P'$ where
			\ben
			\w [(a)] if $X_i$ is not nullable, then $\alpha_i = X_i$;
			\w [(b)] if $X_i$ is nullable, then $\alpha_i$ is either
				$X_i$ or $\epsilon$;
			\w [(c)] not all $\alpha_i$'s are $\epsilon$.
			\een
		\eit
	\w A production of the form $A \rightarrow B$ is called 
		a {\bf{}unit} production. All others including 
		$A \rightarrow \epsilon$ and $A \rightarrow a$ are
		{\bf{}nonunit} productions.
	\w Every CFL without $\epsilon$ is defined by a grammar 
		with no useless symbols, $\epsilon$-productions, or
		unit productions.
	\eit
\eit
\subsection{Chomsky Normal Form}
\bit
\w ({\bf{}Chomsky Normal Form; CNF}) Any context-free language
	without $\epsilon$ is generated by a grammar in which 
	all productions are of the form $A \rightarrow BC$ or
	$A \rightarrow a$. Here, $A, B, C \in V$ and $a \in T$.
	\bit
	\w First, we can transform each $A \rightarrow 
		\alpha_1\cdots{\alpha_k}$
		into $A \rightarrow X_1\cdots{X_k}$ wheren $X_i$'s 
		are variables.
		We achieve this when we replace $X_i \rightarrow \alpha_i$ 
		whenever
		$\alpha_i$ is a terminal.
	\w Now that all the productions are of the form $A \rightarrow a$
		or $A \rightarrow X_1\cdots{X_k}$, we can transform 
		$A \rightarrow X_1\cdots{X_k}$ into a sequence of 
		the productions of the form $A \rightarrow BC$.
		\begin{eqnarray*}
		A & \rightarrow & X_1X_2'\\
		X_2' & \rightarrow & X_2X_3'\\
		X_3' & \rightarrow & X_3X_4'\\
		& \vdots & \\
		X_{k-1}' & \rightarrow & X_{k-1}X_k
		\end{eqnarray*}
	\eit
\eit

\subsection{Greibach Normal Form}
\bit
\w Define an {\bf{}$A$-production} to be a production with variable
	$A$ on the left. Let $G = (V, T, P, S)$ be a CFG. Let
	$A \rightarrow \alpha_1B\alpha_2$ be a production in $P$
	and $B \rightarrow \beta_1 \mid \beta_2 \mid \cdots \mid \beta_r$
	be the set of all $B$-productions. Let $G_1 = (V, T, P_1, S)$
	be obtained from $G$ by deleting the production $A \rightarrow 
	\alpha_1B\alpha_2$ from $P$ and addign productions
	$A \rightarrow \alpha_1\beta_1\alpha_2 \mid \alpha_1\beta_2\alpha_2
	\mid \cdots \mid \alpha_1\beta_2\alpha_2$. Then $L(G) = L(G')$.
\w Let $G = (V, T, P, S)$ be a CFG. Let $A \rightarrow A\alpha_1 \mid
	A\alpha_2 \mid \cdots \mid A\alpha_r$ be the set of 
	$A$-productions for which $A$ is the leftmost symbol of the
	right-hand side. 
	Let $A \rightarrow \beta_1 \mid \cdots \mid \beta_s$ be the
	remaining productions. Let $G_1 = (V\cup\{B\}, T, P_1, S)$
	be the CFG formed by adding the variable $B$ to $V$ and replacing
	all the productions by the productions

	\begin{minipage}[t]{5.5cm}
	\ben
	\w [(a)] $\left\{ \begin{array}{lll} 
		A & \rightarrow & \beta_i \\
		A & \rightarrow & \beta_iB \\
		\end{array}\right\} 1 \le i \le s$,
	\een
	\end{minipage} \ \ 
	\begin{minipage}[t]{5.5cm}
	\ben
	\w [(b)] $\left\{ \begin{array}{lll} 
		B & \rightarrow & \alpha_i \\
		B & \rightarrow & \alpha_iB \\
		\end{array}\right\} 1 \le i \le r$
	\een
	\end{minipage}

	Then $L(G_1) = L(G)$.
	\bit
	\w Above procedure can be coined as `eliminating {\bf{}left
		recursion}.'
	\w See Figure~4.8 of \cite{HU79} for the effect of the procedure.
	\eit
\w ({\bf{}Greibach Normal Form; GNF})
	Every context-free language $L$ without $\epsilon$ can be 
	generated by a grammar for which every production is of the
	from $A \rightarrow a\alpha$, where $A$ is a variable, 
	$a$ is a terminal, and $\alpha$ is a (possibly empty)
	string of variables.
\eit

\subsection{The Existence of Inherently Ambiguous Context-Free Languages}
\bit
\w Let $(N_i, M_i), 1 \le i \le r$, be pairs of sets of integers
	(The sets may be finite or infinite). Let 
		\[ S_i = \{(n, m): n \in N_i, m \in M_i\} \]
	and let
		\[ S = S_1 \cup S_2 \cup \cdots \cup S_r.\]
	If each pair of integers $(n, m)$ is in $S$ for all $n$ and $m$,
	where $n \ne m$, then $(n, n) \in S$ for all but some
	finite set of $n$.
\w The CFL,
	\[ L = \{a^nb^nc^md^m: n \ge 1, m \ge 1\} \cup
		\{a^nb^mc^md^n: n \ge 1, m \ge 1\} \]
	is inherently ambiguous.
\eit

\section{Pushdown Automata}
\bit
\w The pushdown automaton is a {\em{}nondeterministic\/} device
	and the deterministic version accepts only a subset of 
	all CFL's.
	\bit
	\w Fortunately, this subset includes the syntax of most
		programming languages.
	\eit
\eit
\subsection{Definitions}
\bit
\w A {\bf{}nondeterministic pushdown automata} (or {\bf{}PDA})
	$M$ is a system 
	\[(Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)\]
	 where
	\ben
	\w [(a)] $Q$ is a finite set of {\em{}states\/},
	\w [(b)] $\Sigma$ is the {\em{}input 
		alphabet\/}, 
	\w [(c)] $\Gamma$ is the {\em{}output alphabet\/},
	\w [(d)] $q_0 \in Q$ is the {\em{}initial state\/},
	\w [(e)] $Z_0 \in \Gamma$ is a particular stack symbol
			called the {\em{}start symbol\/},
	\w [(f)] $F \subseteq Q$ is the set of {\em{}final states\/}, and
	\w [(g)] $\delta$ is a mapping from $Q \times (\Sigma \cup \{\epsilon\})
		\times \Gamma$ to finite subsets of $Q \times \Sigma^*$.
	\een
\w {\bf{}Moves}
	\bit
	\w The interpretation of 
		\[ \delta(q, a, Z) = \{(p_1, \gamma_1), \cdots, (p_m, \gamma_m)\} \]
		where $q$ and $p_i$ are states, $a \in \Sigma$, $Z$ is a
		stack symbol, and $\gamma_i \in \Gamma^*$, 
		is that {\em{}the PDA in state $q$, with input symbol $a$
		and $Z$ the top symbol on the stack can, for any $i$, 
		enter state $p_i$, replace symbol $Z$ by string
		$\gamma_i$, and advance the input head one symbol\/}.
		\bit
		\w The convention is that the leftmost symbol of $\gamma_i$ will be
			placed highest on the stack.
		\eit
	\w The interpretation of 
		\[ \delta(q, \epsilon, Z) = 
		\{(p_1, \gamma_1), \cdots, (p_m, \gamma_m)\} \]
		is the same as above except for the fact that {\em{}the input
		head is not advanced\/}.
	\eit
\w {\bf{}Instantaneous descriptions}
	\bit
	\w We define an {\bf{}instantaneous description} (or {\bf{}ID})
		to be a triple $(q, w, \gamma)$, where $q$ is a state,
		$w$ a string of input symbols, and $\gamma$ a string of 
		stack symbols.
	\w If $M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)$ is a PDA,
		we say 
			\[ (q, wa, Z\alpha) \vdash_M (p, w, \beta\alpha) \]
		if $\delta(q, a, Z)$ contains $(p, \beta)$.
	\w $\vdash_M^*$ is a reflective, transitive closure of $\vdash_M$
		and $I \vdash_M^i I'$ means $i$-step derivation of $I'$ from $I$.
	\eit
\w For PDA $M = (Q, \Sigma, \Gamma, \delta_0, q_0, Z_0, F)$, we define
	$L(M)$, the {\bf{}language accepted by final state}, to be
		\[ \{w: (q_0, w, Z_0) \vdash_M^* (p, \epsilon, \gamma)
			\mbox{\ for some $p \in F$ and $\gamma \in \Gamma^*$}\}.\]
\w We define $N(M)$, the {\bf{}language accepted by empty stack}, to be
	\[ \{w: (q_0, w, Z_0) \vdash_M^* (p, \epsilon, \epsilon)
		\mbox{\ for some $p \in Q$}\}. \]
\w {\bf{}Deterministic PDAs}
	\bit
	\w A PDA $M = (Q, \Sigma, \Gamma, \delta_0, q_0, Z_0, F)$ is 
		{\bf{}deterministic} if:
		\ben
		\w [(a)] for each $q \in Q$ and $Z \in \Gamma$, 
			whenever $\delta(q, \epsilon, Z)$ is nonempty,
			then $\delta(q, a, Z)$ is empty for all
			$a \in \Gamma$, and
		\w [(b)] for no $q \in Q$, $Z \in \Gamma$, and
			$a \in \Sigma \cup \{\epsilon\}$ does
			$\delta(q, a, Z)$ contain more than one
			element.
		\een
	\eit
\eit

\subsection{Pushdown Automata and Context-Free Languages}
\bit
\w {\bf{}Equivalence of acceptance by final state and empty stack}
	\bit	
	\w If $L = L(M_1)$ from some PDA $M_1$, then
		$L = N(M_2)$ for some PDA $M_2$.
		\bit
		\w Let $M_2$ simulate $M_1$ by letting $M_2$ erase its
			stack whenever $M_1$ enters a final state.
		\eit
	\w If $L = N(M_2)$ from some PDA $M_2$, then
		$L = L(M_1)$ for some PDA $M_1$.
		\bit
		\w Our plan now is to have $M_1$ simulate $M_2$ and detect
			when the $M_2$ empties its stack.
		\eit
	\eit
\w {\em{}If $L$ is a context-free language, then there exists a PDA $M$
	s.t. $L = N(M)$.\/}
	\bit
	\w Given a grammar $G = (V, T, P, S)$ in {\em{}Greibach normal
		form\/}, let
			\[ M = (\{q\}, T, V, \delta, q, S, \emptyset) \]
		be a PDA s.t.
		$\delta(q, a, A)$ contains $(q, \gamma)$ whenever
		$A \vdash^*_M a\gamma$ is in $P$.
	\w Since $G$ is in GNF, each sentential form in a leftmost derivation
		consists of a string of terminals $x$ followed by a string
		of variables $\alpha$.
	\w Now prove that ``$S \stackrel{*}{\Ra} x\alpha$ iff
		$(q, x, S) \vdash^*_M (q, \epsilon, \alpha)$.''
	\eit
\w {\em{}If $L = N(M)$ for some PDA $M$, then $L$ is a context-free 
	language.\/}
	\bit
	\w Let $M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, \emptyset)$ be
		a PDA. Let $G = (V, \Sigma, P, S)$ be a CFG where
		\ben
		\w [(a)] $V = \{S\} \cup \{[q, A, p]: q \in Q, p \in Q, 
			A \in \Gamma\}$ and
		\w [(b)] $P$ is the set of productions,
			\ben
			\w [1)] for each $q \in Q$,
			\[S \rightarrow [q_0, Z_0, q] \]
			\w [2)] for each $q, q_1, \cdots, q_{m+1} \in Q$,
				for each
				$a \in \Sigma \cup \{\epsilon\}$, and 
				for each $A, B_1, \cdots, B_m \in \Gamma$,
			\[[q, A, q_{m+1}] \rightarrow
				a[q_1, B_1, q_2][q_2, B_2, q_3]\cdots[q_m, B_m, q_{m+1}]\]
				s.t.
				$\delta(q, a, A)$ contains $(q_1, B_1B_2\cdots{B_m})$.
			\een
		\een
	\w Now prove that 
		\[ [q, A, p] \stackrel{*}{\Ra} x \mbox{\ iff\ }
			(q, x, A) \vdash^*_M (p, \epsilon, \epsilon). \]
	\eit
\eit

\subsection{Two-Way Pushdown Automata}
\bit
\w A {\bf{}two-way pushdown automaton} (or {\bf{}2PDA}) is a PDA
	that is permitted to move either way on its input.
\w $L = \{0^n1^n2^n: n \ge 1\}$ is accepted by a 2PDA.
	\bit
	\w Above $L$ is not accepted by a PDA; so 2PDA's are not equivalent
	to PDA's.
	\eit
\eit

\section{Properties of Context-Free Languages}
\subsection{The Pumping Lemma for CFL's}
\bit
\w ({\bf{}Pumping Lemma for Context-Free Languages})
	Let $L$ be any CFL. Then there is a constant $n$, depending 
	only on $L$, such that if $z \in L$ and $|z| \ge n$, then
	we may write $z = uvwxy$ s.t.
	\ben
	\w [(a)] $|vx| \ge 1$,
	\w [(b)] $|vwx| \le n$, and
	\w [(c)] for all $i \ge 0$, $uv^iwx^iy \in L$.
	\een
\w The following languages are {\em{}non-context-free languages}.		
	\ben
	\w $L_1 = \{a^ib^ic^i : i \ge 1\}$.
	\w $L_2 = \{a^ib_ic^j : j \ge i\}$.
	\w $L_3 = \{a^ib^jc^k : i \le j \le k\}$.
	\w $L_4 = \{a^ib^jc^id^j : i \ge 1, j \ge 1\}$.
	\een
\w {\em{}There are some non-CFL's for which the pumping lemma
	is of no help\/}. E.g.,
		\[ L_5 = \{a^ib^jc^kd^l: \mbox{either $i = 0$ or $i = k = l$}\}\]
	is not context-free but cannot prove its non-context-freeness
	using the pumping lemma.
	\bit
	\w $L_5$ can be proved to be non-context-free using
		{\em{}Ogden's lemma\/}.
	\w $L_6 = \{a^ib^jc^k: i \ne j, j \ne k, \mbox{\ and\ } i \ne k\}$
		also surrenders to Ogden's lemma.
	\eit
\w ({\bf{}Ogden's Lemma}) Let $L$ be a CFL. Then there is a constant
	$n$ (which may in fact be the same as for the pumping lemma)
	such that if $z$ is any word in $L$, and we mark any $n$ or more
	positions of $z$ ``distinguished,'' then we can write
	$z = uvwxy$, such that:
	\ben
	\w [(a)] $v$ and $x$ together have at least one distinguished
		position,
	\w [(b)] $vwx$ has at most $n$ distinguished positions, and
	\w [(c)] for all $i \ge 0$, $uv^iwx^iy$ is in $L$.
	\een
\w The pumping lemma is a special case of Ogden's lemma where
	all positions are distinguished.
\eit

\subsection{Closure Properties of CFL's}
\bit
\w The CFL's are closed under union, cancatenation and
	Kleene closure.
\w The CFL's are closed under substitution.
	\bit
	\w The CFL's are closed under homomorphism.
	\eit
\w The CFL's are closed under inverse homomorphism.
\w The CFL's are {\em{}not\/} closed under intersection.
	\bit
	\w The CFL's are not closed under complementation.
	\eit
\w If $L$ is a CFL and and $R$ is a regular set, then
	$L \cap R$ is a CFL.
\eit

\subsection{Decision Algorithms for CFL's}
\bit
\w There are algorithms to determine if a CFL is 
	(a) empty, (b) finite, or (c) infinite.
\w Given a CFG $G = (V, T, P, S)$ and string $x \in T^*$,
	is $x \in L(G)$?
	\bit
	\w Earley's algorithm solves this problem in $O(n^3)$ time in general,
		and $O(n^2)$ on unambiguous CFG, but actually linear
		on a wide variety of useful grammars.
	\eit
\eit

\section{Turing Machines}
\subsection{The Turing machine model}
\bit
\w A {\bf{}Turing machine} is a $7$-tuple 
	$M = (Q, \Sigma, \Gamma, \delta, q_0, q_A, q_R)$, where
	$Q, \Sigma, \Gamma$ are finite sets and
	\ben
	\w [(a)] $Q$ is the set of {\bf{}states},
	\w [(b)] $\Sigma$ is the {\bf{}input alphabet} not containing
		the {\bf{}blank symbol}, $\Box$,
	\w [(c)] $\Gamma$ is the {\bf{}tape alphabet}, where
		\[\{\Box\} \in \Gamma \mbox{\ and\ } 
			\Sigma \subseteq \Gamma,\]
	\w [(d)] $\delta: Q\times\Gamma \rightarrow 
		Q\times\Gamma\times\{L, R\}$
		is the {\bf{}transition function},
	\w [(e)] $q_0 \in Q$ is the {\bf{}start state},
	\w [(f)] $q_A \in Q$ is the {\bf{}accept state}, and
	\w [(g)] $q_R \in Q$ is the {\bf{}reject state}, where $q_A \ne q_R$.
	\een
\w A Turing machine $M$ receives its input $w = w_1w_2\cdots{w_n} \in 
	\Sigma^*$ on the leftmost $n$ squares of the tape, and the rest
	of the tape is blank.
	\bit
	\w The computation continues until it enters either the accept
		or reject states at which point it halts. 
	\w If neither occurs, $M$ goes on forever. A {\bf{}loop}!\footnote{not
		in the sence of `cycle'}
	\eit
\w A {\bf{}configuration}\footnote{or {\bf{}instantaneous description}} 
	of $M$ is defined to be $uqv$ where $q \in Q$ and $u, v \in \Gamma^*$.
	\bit
	\w $q$ is the {\bf{}current state}.
	\w $u, v$ indicates the {\bf{}current tape contents} and the 
		{\bf{}current head position}.
	\w $car(v)$ is the content of the table under the tape head.
	\eit
\w A configuration $C_1$ {\bf{}yields} configuration $C_2$, denoted
	$C_1 \vdash C_2$, if the Turing 
	machine can legally go from $C_1$ to $C_2$ in a single step. I.e.,
	for $u, v \in \Gamma^*$, $q_i, q_j \in Q$, and $a, b \in \Gamma$,
	\bit
	\w $uaq_ibv \vdash uq_jacv$ if $\delta(q_i, b) = (q_j, c, L)$.
	\w $uaq_ibv \vdash uacq_jv$ if $\delta(q_i, b) = (q_j, c, R)$.
	\eit
\w The {\bf{}start configuration} of $M$ on input $w$ is the configuration
	$q_0w$.
\w In an {\bf{}accepting configuration}, the state of configuration is
	$q_A$.
\w In a {\bf{}rejecting configuration}, the state of configuration is
	$q_R$.
\w Accepting and rejecting configurations are called
	{\bf{}halting configurations} and do not yield further computation.
\w A {\sl\bfseries{}Turing machine accepts input $w$\/} 
	if a sequence of configurations
	$C_1, C_2, \cdots, C_k$ exists s.t.
	\ben
	\w [(a)] $C_1$ is the start configuration of $M$ on input $w$,
	\w [(b)] $C_i \vdash C_{i+1}$, $1 \le i < k$, and
	\w [(c)] $C_k$ is an {\em{}accepting\/} configuration.
	\een
\w The {\bf{}language of $M$}, $L(M)$, is the
	set of string that $M$ {\em{}accepts\/}. 
\w A language $L$ is {\bf{}Turing-acceptable} or 
	{\bf{}recursively enumerable} ({\bf{}R.E.})
	if some Turing machine {\bf{}accepts}\footnote{Sipser prefers to
	say `recognizes' lest `accepts' is overloaded with two meanings:
	$M$ accepts $w$ and $M$ accepts $L$.} it.
	\bit
	\w In this case, $M$ may not halt for some inputs.
	\w Given a class $C$ of languages, 
		\[ \mbox{co-}C = \{L \subseteq \Sigma^*: 
		\overline{L} \in C\}.\]
	\w A language $L$ is {\bf{}co-R.E.} or {\bf{}co-Turing-acceptable}
		if some Turing machine
		accepts $\overline{L}$; that is, $\overline{L}$ is
		r.e. or Turing-acceptable.
	\eit
\w A language $L$ is {\bf{}Turing-decidable} or {\bf{}recursive}
	if some Turing machine {\bf{}decides} it.
	\bit
	\w For a decidable language $L$, there exists $M$ s.t.
		$M$ always halts (accepts or rejects) on inputs. 
	\w That is,
		$M$ always gives an answer to the question ``$w \in L$?''
	\eit
\w The following three `classes' of languages can be defined from the
	above definition:
	\begin{eqnarray*}
	\mbox{R}  & = & \{L: L\mbox{\ is Turing-decidable}\}\\
	\mbox{R.E.} & = & \{L: L\mbox{\ is Turing-acceptable}\} \\
	\mbox{co-R.E.} & = & \{L: \overline{L}\mbox{\ is Turing-acceptable}\} 
	\end{eqnarray*}
\eit

\subsection{Linear bounded automata}
\bit
\w A {\bf{}linear bounded automaton (LBA)} is a restricted type of Turing 
	machine wherein the tape head isn't permitted to move off the
	portion of the tape containing the {\em{}input\/}.
	\bit
	\w An LBA is a Turing machine with a limited amount of memory.
	\w LBAs are quite powerful as we shall see in that
	deciders for 
	{\sf{}Accepts$_{\mbox{\scriptsize{}DFA}}$},
	{\sf{}Accepts$_{\mbox{\scriptsize{}CFG}}$},
	{\sf{}AcceptsNothing$_{\mbox{\scriptsize{}DFA}}$}, and
	{\sf{}AcceptsNothing$_{\mbox{\scriptsize{}CFG}}$} are 
	LBAs.
	\eit
\w Let $M$ be an LBA with $q$ states and $g$ symbols in the tape alphabet.
	There are exactly $qng^n$ distinct configurations of $M$ for a tape
	of length $n$.
\eit

\subsection{Enumerators}
\bit
\w An {\bf{}enumerator} is a Turing machine variant which
	prints a possibly infinite list of string.
	\bit
	\w $E$ may generate the strings of the language in any order,
		{\em{}possibly with repetitions\/}.
	\eit
\w A {\bf{}language enumerated by $E$} is the collection of
	all strings that $E$ eventually prints out.
\w {\sl\bfseries{}A language $L$ is 
	Turing-acceptable (r.e.) iff some enumerator enumerates $L$\/}.
	\bit
	\w Proof of $(\Rightarrow)$ uses {\bf{}Cantor's first diagonal
		method\/} (a.k.a {\bf{}dovetailing}).
		\bit
		\w Let $M$ be a acceptor for $L$; then design $M'$ such that
			$M'$ simulates $M$ on all possible inputs 
			$w_1, w_2, \cdots$.
		\w This cannot be done just with `time-sharing' since 
			the possible inputs are infinite; hence the 
			dovetailing! 
		\eit
	\eit
\w {\sl\bfseries{}A language $L$ is 
	recursive iff some enumerator enumerates $L$ in
	canonical order.\/}
	\bit
	\w Proof of $(\Leftarrow)$ shows some difficulty: when $L$
		is finite, though we have an enumerator, 
		we have no way of building a Turing
		machine that decides $L$. 
	\w (cont.) Let $E$ be a enumerator and
		suppose that we want to build a TM $M$ that decides $L$
		using $E$ as a subroutine. 
	\w (cont.) That is given a string $w$, we want a TM $M$ that decides
		whether $w \in L$ by simulating $E$ to see where $E$ generates
		$w$.
	\w (cont.) If $L$ is infinite, the above strategy works, since 
		there are infinitely many strings in $L$ that comes 
		canonically after $w$:
		\[ \cdots, w, w', w'', \cdots. \]
		Since $w'$ should be generated by $E$, so should $w$.
	\w (cont.) Suppose that $L$ is {\em{}finite\/} 
		and $w_0$ is the last string
		in $L$. Given a input string $w$ 
		that may come canonically after $w_0$,
		we do not know whether $w$ is generated by $L$ or not.
	\w (cont.) Unfortunately, {\em{}we cannot determine whether $E$
		generates a finite set or, if finite, which finite set
		it is\/}. Hence we do not know what's the last string 
		$w_0$ generated by $E$.
			
	\eit
\eit


\subsection{Basic properties of recursive and r.e. sets}
\bit
\w {{}If $L$ is Turing-decidable then $L$ is Turing-acceptable\/}.
\w {{}The set of Turing-decidable languages is closed under
	{\em{}complementation\/}.}
	\bit
	\w I.e. if $L$ is recursive, then $\overline{L}$ is recursive.
	\w The set of Turing-decidable languages is closed under
		{\em{}union\/} and {\em{}intersection\/}.
	\eit
\w {{}$L$ is Turing-decidable iff both $L$ and $\overline{L}$ is 
	Turing-acceptable\/}.
	\bit
	\w In other words, 
		$L$ is decidable iff $L$ is both Turing-acceptable and
		co-Turing-acceptable.
	\eit
\w {{}The set of Turing-acceptable languages is {\sl\bfseries{}not\/}
	closed under complementation\/}.
		\bit
		\w So, Turing-acceptability of $L$ does not
			imply the Turing-decidability of $L$.
		\w {\em{}The set of Turing-acceptable languages is closed under
			union and intersection\/}.
		\eit
\w As a consequence of above theorems, 
	given a pair of complementary languages, $L$ and $\overline{L}$,
	only one of the three following condition holds:
	\ben
	\w [(a)] both $L$ and $\overline{L}$ is recursive
	\w [(b)] neither $L$ nor $\overline{L}$ is r.e.
	\w [(c)] one of $L$ and $\overline{L}$ is r.e. and the other is
		not r.e. (the r.e. one is not recursive, since the 
		complementary
		one would also be recursive otherwise)
	\w [(*)] {\em{}So, given $L$, if we could prove that $\overline{L}$ is
		not r.e., we know that $L$ is either non-r.e. or
			`r.e. but not recursive' by (b) and (c); which proves
			the {\sl\bfseries{}undecidability} of $L$}.
	\een
\w Let $A$ and $B$ be two disjoint languages. The language $C$
	{\bf{}separates} $A$ and $B$ if $A \subseteq C$ and
	$B \subseteq \overline{C}$. 
	\bit
	\w Any two disjoint co-Turing-acceptable languages are separable
	by some decidable language.
	\eit
\eit

\section{Decidable Languages}
\subsection{Decidable problems concerning regular languages}
\bit
\w ({\bf{}The Acceptance Problem for DFAs})
	\bit
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}DFA}}$} $=
		\{\arc{B, w}:$ $B$ is a DFA that accepts input string $w\}$.
	\w {\bf{}Problem}: Does a DFA $B$ accept input string $w$?
	\w {\em{}The problem of testing whether a DFA $B$ accepts an input
		string $w$ is the same as the problem of testing
		whether $\arc{B, w}$ is a member of the language
		{\sf{}Accepts$_{\mbox{\scriptsize{}DFA}}$}}.
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}DFA}}$} is decidable.
	\eit
\w ({\bf{}The Acceptance Problem for NFAs})
	\bit
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}NFA}}$} $=
		\{\arc{B, w}:$ $B$ is a NFA that accepts input string $w\}$.
	\w {\bf{}Problem}: Does an NFA $B$ accept input string $w$?
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}NFA}}$} is decidable.
	\w Note that an equivalent DFA can be constructed from an NFA
		by {\em{}subset construction\/}. That is, 
		{\sf{}Accepts$_{\mbox{\scriptsize{}NFA}}$} is reducible
		to {\sf{}Accepts$_{\mbox{\scriptsize{}DFA}}$}.
		
	\eit
\w ({\bf{}The Acceptance Problem for Regular Expressions})
	\bit
	\w {\sf{}Accepts\footnote{Perhaps the more plausible name for this
	problem would be 
	{\sf{}Generates$_{\mbox{\scriptsize{}REX}}$}.}$_{\mbox{\scriptsize{}REX}}$} $=
		\{\arc{R, w}:$ $R$ is a regular expressions that generates
		$w\}$.
	\w {\bf{}Problem}: Does a regular expression $R$ generate $w$?
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}REX}}$} is decidable.
	\w Note that an equivalent DFA can be constructed from a regular
		expression by {\em{}Thompson's construction\/}.
	\eit
\w ({\bf{}The Emptiness Problem for DFAs})
	\bit
	\w {\sf{}AcceptsNothing$_{\mbox{\scriptsize{}DFA}}$} $=
		\{\arc{B}:$ $B$ is a DFA and $L(B) = \emptyset\}$.
	\w {\bf{}Problem}: Does a DFA accept nothing?
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}DFA}}$} is decidable.
	\w A DFA accepts some string iff reaching an `accepting state'
		from the start state is possible, which can be found
		by well-known graph traversal algorithms.
	\eit
\w ({\bf{}The Equivalence Problem for DFAs})
	\bit
	\w {\sf{}Equiv$_{\mbox{\scriptsize{}DFA}}$} $=
		\{\arc{A, B}:$ $A, B$ are DFAs and $L(A) = L(B)\}$.
	\w {\bf{}Problem}: Do DFAs $A$ and $B$ accept the same language?
	\w {\sf{}Equiv$_{\mbox{\scriptsize{}DFA}}$} is decidable.
	\w Since regular sets are closed under union and complementation, 
		\[ L(C) = (L(A) \cap \overline{L(B)}) \cup
		(\overline{L(A)} \cap L(B))\]
		is {\em{}nonempty\/} iff $L(A) \ne L(B)$.
	\w That is, given that $C$ is a DFA that accepts $L(C)$,
		{\sf{}Equiv$_{\mbox{\scriptsize{}DFA}}$} is reducible
		to the problem:
		\[ \arc{C} \in \mbox{\ \sf{}AcceptsNothing$_{\mbox{\scriptsize{}DFA}}$}.\]
	\eit
\eit

\subsection{Decidable problems concerning context-free languages}
\bit
\w ({\bf{}The Acceptance Problem for CFGs})
	\bit
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}CFG}}$} $=
		\{\arc{G, w}:$ $G$ is a CFG that generates string $w\}$.
	\w {\bf{}Problem}: Does a CFG $G$ generate $w$?
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}CFG}}$} is decidable.
	\w If $G$ were in {\em{}Chomsky-normal form\/}, any derivation of
		$w$ has $2n-1$ steps if $|w| = n$. Note that any CFG $G$
		can be converted to Chomsky-normal forms.
	\eit
\w ({\bf{}The Emptiness Problem for CFGs})
	\bit
	\w {\sf{}AcceptsNothing$_{\mbox{\scriptsize{}DFA}}$} $=
		\{\arc{G}:$ $G$ is a CFG and $L(G) = \emptyset\}$.
	\w {\bf{}Problem}: Does a CFG generate nothing?
	\w {\sf{}AcceptsNothing$_{\mbox{\scriptsize{}CFG}}$} is decidable.
	\w This problem can be restated as that of 
		determining whether a start nonterminal can
		derive a non-$\epsilon$ string.
	\eit
\eit

\subsection{Decidable problems concerning linear bounded automata}
\bit
\w ({\bf{}The Acceptance Problem for LBAs})
	\bit
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}LBA}}$} $= 
		\{\arc{M, w}:$ $M$ is an LBA, $w \in \Sigma^*$, and
			$M$ accepts $w\}$.
	\w {\bf{}Problem}: Does the LBA $M$ accept $w$?
	\w Simulate $M$ on $w$; if it halts and accepts/rejects, that's
		fine. The difficulty occurs if $M$ loops on $w$.
	\w (cont.) In case of loop, we need to detect looping so that
		we can halt and reject.
	\w (cont.) Since, $q$-state, $g$-symbol LBA with input string
		of length $n$ has exactly $qng^n$ distinct configurations,
		we know that if $M$ does not halt in $qng^n$ steps, 
		it is in a loop!
	\eit
\eit

\subsection{Relationship among classes of languages}
\bit
\w {\sl\bfseries{}Every context-free languages is decidable\/}.
\w The relationship on language class containment:
	\[\mbox{Regular $\subseteq$ Context-free $\subseteq$
	Decidable $\subseteq$ Turing-acceptable}\]
\eit


\section{Undecidability}
\subsection{Two main techniques for proving undecidability of languages}
\bit
\w \fbox{\sl\bfseries{}Diagonalization}
\w \fbox{\sl\bfseries{}Many-one reducibility}
\eit


\subsection{Proving the undecidability of the halting problem by 
	diagonalization}
\bit
\w {\sl\bfseries{}{\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} is 
	not recursive (undecidable)}.
	\ben
	\w {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} $=
		\{\arc{M, w}:$ $M$ is a TM, $w \in \Sigma^*$, and
		$M$ halts on $w\}$.
	\w To prove this, we will prove that the related language $K$ is not
		recursive.
		\[ K =
		\{\arc{M}: \mbox{\ $M$ is a TM and $M$ halts on \arc{M}}\}.\]
		\bit
		\w $K$ is a special case of 
			{\sf{}Halting$_{\mbox{\scriptsize{}TM}}$}.
		\w So, if $K$ is undecidable then the more general version,
			{\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} is
			also undecidable.
		\w That is, $K \le_m$ {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$}.
		\w Now, what's left is to prove {\sl\bfseries{}$K$ is not
			recursive\/}.
		\eit
	\w {\sl\bfseries{}To prove that $K$ is not recursive, we prove
		that $\overline{K}$ is not r.e.\/}
		\bit	
		\w This is due to the fact that only one of the following
			condition holds:
			\ben
			\w [(a)] both $K$ and $\overline{K}$ is recursive;
			\w [(b)] neither $K$ nor $\overline{K}$ is r.e.
			\w [(c)] one of $K$ and $\overline{K}$ is r.e.
				and the other is non-r.e.; the non-r.e.
				one is not recursive.
			\een
		\w $\overline{K}$ is defined as:
		\[ \overline{K} =
			\{\arc{M}: \mbox{\ $M$ is a TM and $M$ does not halt 
			on \arc{M}}\}.\]
		\eit
	\w {\sl\bfseries{}Now, let's prove that $\overline{K}$ is not r.e.\/}
		\bit
		\w Suppose, to the contrary, that $\overline{K}$ is 
			Turing-acceptable.
		\w Then there exists a TM $M_0$ that halts exactly on
			the encodings of the elements of $\overline{K}$.
		\w That is, $M_0$ halts on $\arc{M}$ exactly when
			$M \in \overline{K}$.
		\w In other words, {\sl\bfseries{}$M_0$ halts exactly when 
			$M$ does not halt on the encoding of itself!\/}
		\eit
	\w Consider what $M_0$ does on ``its own'' encoding. That is,
		{\sl\bfseries{}let $M_0$ run with $\arc{M_0}$ as its input.\/}
		\bit
		\w {\sl\bfseries{}$M_0$ halts on $\arc{M_0}$ exactly
		when $M_0$ does not halt on $\arc{M_0}$.}
		\w {\em{}A contradiction!\/}
		\eit
	\een
\w ``Diagonalization'' used in the above proof (step 4 and 5)
	\bit
	\w Let $M_1, M_2, \cdots$ be a canonical ordering of {\em{}all\/}
		Turing machines.
	\w Let's build a 2-dimensional table $K^c$ indexed by Turing machines
		and its encodings where
		\[ K^c(i, j) = \left\{\begin{array}{ll}
				1, & \mbox{if\ } M_i \mbox{\ halts on\ } \arc{M_j},\\
				0, & \mbox{if\ } M_i \mbox{\ doesn't halt on\ } \arc{M_j}.
				\end{array}\right. \]
	\w We have defined $M_0$ so that $M_0(\arc{M_i})$ halts
		iff $M_i(\arc{M_i})$ does not halt.
	\w Thus the behavior of $M_0$ differs from the $i$th TM at
		the $(i, i)$th entry in the table.
	\eit
\eit

\subsection{Many-one reducibility}
\paragraph{Basic properties}
\bit
\w If $A \subseteq \Sigma^*$ and $B \subseteq \Sigma^*$ are two
	languages, we say that $A$ is {\bf{}many-one reducible}\footnote{or 
	{\bf{}mapping reducible}} to $B$,
	written $A \le_m B$	if there exists some (total) function
	$f: \Sigma^* \rightarrow \Sigma^*$ which is Turing-computable
	s.t. for all strings $x \in \Sigma^*$, $x \in A$ iff
	$f(x) \in B$.
\w {\sl\bfseries{}If $A \le_m B$ and $B$ is decidable then
	$A$ is decidable.}
	\bit
	\w {\sl\bfseries{}If $A \le_m B$ and $A$ is undecidable then
		$B$ is undecidable.}
	\eit
\w $A$ is {\bf{}many-one equivalent} to $B$, written $A =_m B$
	iff $A \le_m B$ and $B \le_m A$.
\w If $A \le_m B$ and $B$ is r.e. then $A$ is r.e.
	\bit
	\w If $A \le_m B$ and $A$ is not r.e. then $B$ is not r.e.
	\eit
\w $A \le_m B$ iff $\overline{A} \le_m \overline{B}$.
\w {\sl\bfseries{}If $A$ is r.e. but not recursive, then
	$A$ and $\overline{A}$ are `$\le_M$-incomparable';
	that is, neither $A \le_m \overline{A}$ nor
	$\overline{A} \le_m A$.}
\eit
\paragraph{Reductions via computation histories}
\bit
\w Given a Turing machine $M$ and an input string $w$,
	an {\bf{}accepting history for $M$ on $w$} is a sequence
	of configurations, $C_1, C_2, \cdots, C_l$, where $C_1$ is the
	start configuration of $M$ on $w$, $C_l$ is an accepting 
	configuration of $M$, and each $C_i$ legally follows from $C_{i-1}$.
\w A {\bf{}rejecting computation history for $M$ on $w$} is 
	defined similarly, except that
	$C_l$ is a rejecting configuration
\w Computation histories are finite sequences.
\w Reduction via computation histories was used 
	to prove the undecidability of Hilbert's Tenth Problem.
\eit

\subsection{Rice's theorem}
\bit
\w As we shall see, 
	{\sf{}Regular$_{\mbox{\scriptsize{}TM}}$} or 
	{\sf{}ContextFree$_{\mbox{\scriptsize{}TM}}$} is undecidable;
	in fact, Rice's Theorem states that {\sl\bfseries{}testing 
	`any' property
	of the languages accepted by Turing machines is undecidable\/}.
\w ({\bf{}Rice's Theorem})
	{\sl\bfseries{}Let 
	$P$ be any problem about Turing machines that satisfies
	the following two properties. As usual we express $P$ as a 
	language.
	\ben
	\w [\bf{}(a)] For any TMs $M_1$ and $M_2$, where $L(M_1) = L(M_2)$,
		we have $\arc{M_1} \in P$ iff $\arc{M_2} \in P$. 
	\w [\bf{}(b)] There exists TMs $M_1$ and $M_2$, where 
		$\arc{M_1} \in P$ and $\arc{M_2} \not\in P$. 
	\een
	Then, $P$ is undecidable.}
\w Condition (a) states that 
	the membership of a TM $M$ in $P$ depends only
	on the language of $M$.
\w Condition (b) states that
	$P$ is nontrivial -- it holds for some, but not all, TMs.
\w Both the conditions (a) and (b) are {\em{}necessary\/} for Rice's
	Theorem.
\eit






\section{Compendium of Undecidable Languages}
\subsection{Undecidable languages concerning context-free languages}
\bit
\w ({\bf{}The Totality Problem for CFGs})
	\bit
	\w {\sf{}AcceptsAll$_{\mbox{\scriptsize{}CFG}}$} $=
		\{\arc{G}:$ $G$ is a CFG and $L(G) = \Sigma^*\}$.
	\w {\bf{}Problem}: Does a CFG $G$ generate all strings?
	\w {\sf{}AcceptsAll$_{\mbox{\scriptsize{}CFG}}$} is undecidable.
	\eit
\w ({\bf{}The Equivalence Problem for CFGs})
	\bit
	\w {\sf{}Equiv$_{\mbox{\scriptsize{}CFG}}$} $=
		\{\arc{G, H}:$ $G, H$ are CFGs and $L(G) = L(H)\}$.
	\w {\bf{}Problem}: Do CFGs $G$ and $H$ generate the same language?
	\w {\sf{}Equiv$_{\mbox{\scriptsize{}CFG}}$} is undecidable.
	\w Since context-free languages are {\em{}not\/} closed under 
		complementation, we {\em{}cannot\/} use the following:
		\[ L(I) = (L(G) \cap \overline{L(H)}) \cup
		(\overline{L(G)} \cap L(H)).\]
	\eit
\eit
\subsection{Undecidable problems concerning linear bounded automata}
\bit
\w ({\bf{}The Emptiness Problem for LBAs})
	\bit
	\w {\sf{}AcceptsNothing$_{\mbox{\scriptsize{}LBA}}$} $=
		\{\arc{M}:$ $M$ is an LBA and $L(G) = \emptyset\}$.
	\w {\bf{}Problem}: Does an LBA $M$ accept nothing?
	\w {\sf{}AcceptsNothing$_{\mbox{\scriptsize{}LBA}}$} is undecidable.
	\w \am\ $\le_m$ {\sf{}AcceptsNothing$_{\mbox{\scriptsize{}LBA}}$}
	\eit
\eit
\subsection{Undecidable problems concerning Turing machines}
\bit
\w ({\bfseries{}The Acceptance Problem for Turing Machines})
	\bit
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}TM}}$} $= 
		\{\arc{M, w}:$ $M$ is a TM, $w \in \Sigma^*$, and
			$M$ accepts $w\}$.
	\w {\bf{}Problem}: Does $M$ accept $w$?
%	\w {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} $\equiv$
%		{\sf{}Accepts$_{\mbox{\scriptsize{}TM}}$} 
	\w {\sf{}Accepts$_{\mbox{\scriptsize{}TM}}$} is r.e. but not
		decidable.
		\bit
		\w This implies that $\overline{\mbox{\am}}$
			is not r.e. since otherwise \am\
			would be decidable.
		\eit
	\w {\sl\bfseries{}Proof of the undecidability of
	the acceptance problem\/}:\\
	Assume that \am\ is Turing-decidable and let $H$ be a decider for 
	\am. Then
	\ben
	\w $H$ halts and accepts if $M$ accepts $w$.
	\w $H$ halts and rejects if $M$ doen not accept $w$.
	\een
	That is,
	\[H(\arc{M, w}) = \left\{\begin{array}{ll}
		accept & \mbox{if $M$ accepts $w$},\\
		reject & \mbox{if $M$ does not accept $w$}.
			    \end{array}\right.
	\]
	Now, let's construct a TM $D$ with input $\arc{M}$
	which uses $H(\arc{M, \arc{M}})$ as its subroutine\footnote{Note that
	this argument assumes that a TM can simulate the machine 	
	`described by' $\arc{M}$.}, where
	\[D(\arc{M}) = \left\{\begin{array}{ll}
		accept & \mbox{if $M$ does not accept $\arc{M}$},\\
		reject & \mbox{if $M$ accepts $\arc{M}$}.
			    \end{array}\right.
	\]
	Finally, run $D$ with its own description $\arc{D}$ as its input.
	Then, we get
	\[D(\arc{D}) = \left\{\begin{array}{ll}
		accept & \mbox{if $D$ does not accept $\arc{D}$},\\
		reject & \mbox{if $D$ accepts $\arc{D}$}.
			    \end{array}\right.
	\]
	This is a contradiction.
%	}.
	\eit
\w \fbox{\bfseries{}The Halting Problem for Turing Machines}
	\bit
	\w {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} $= 
		\{\arc{M, w}:$ $M$ is a TM, $w \in \Sigma^*$, and
			$M$ halts on $w\}$.
	\w {\bf{}Problem}: Does $M$ halt on $w$?
	\w \am\ $\le_m$ \hm
	\eit
\w ({\bf{}The Hanging Problem for Turing Machines})
	\bit
	\w {\sf{}Hanging$_{\mbox{\scriptsize{}TM}}$} $= 
		\{\arc{M, w}:$ $M$ is a TM, $w \in \Sigma^*$, and
			$M$ hangs on $w\}$.
	\w {\bf{}Problem}: Does $M$ hang on $w$?
	\w {\sf{}Hanging$_{\mbox{\scriptsize{}TM}}$} is r.e.
	\eit
\w ({\bf{}The Blank Tape Halting Problem for Turing Machines})
	\bit
	\w {\sf{}BlankTape$_{\mbox{\scriptsize{}TM}}$} $= 
		\{\arc{M}:$ $M$ is a TM, $M$ 
			halts on $\epsilon\}$.
	\w {\bf{}Problem}: Does $M$ halt on $\epsilon$?
	\w {\sf{}BlankTape$_{\mbox{\scriptsize{}TM}}$} is r.e.
	\w {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} 
		$\le_m$
		{\sf{}BlankTape$_{\mbox{\scriptsize{}TM}}$} 
		\bit
		\w {\sf{}BlankTape$_{\mbox{\scriptsize{}TM}}$} 
			$\le_m$
			{\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} 
		\eit
	\eit
\w ({\bf{}The Emptiness Problem for Turing Machines})
	\bit
	\w {\sf{}AcceptNothing$_{\mbox{\scriptsize{}TM}}$} $= 
		\{\arc{M}:$ $M$ is a TM and $L(M) = \emptyset\}$.
	\w {\bf{}Problem}: Does $M$ accept nothing?
	\w \am\ $\le_m$ {\sf{}AcceptNothing$_{\mbox{\scriptsize{}TM}}$}
	\w Let $E$ be the decider for 
		{\sf{}AcceptNothing$_{\mbox{\scriptsize{}TM}}$} and
		let $\arc{M, w}$ be an input string for \am.
	\w (cont.) Now we'd like to build a decider $A$ that decides \am.
	\w (cont.) Modify $\arc{M}$ such that $M$ rejects all strings
		in $\Sigma^* - \{w\}$ and if the input is $w$ returns the
		result of running $M$ on $w$. Let's denote this modified
		description of $\arc{M}$ by $\arc{M'}$
	\w (cont.) Then $E(\arc{M'}) = accept$ iff $M$ does not accept $w$.
	\eit
\w ({\bf{}The Nonemptiness Problem for Turing Machines})
	\bit
	\w {\sf{}AcceptSomething$_{\mbox{\scriptsize{}TM}}$} $= 
		\{\arc{M}:$ $M$ is a TM and there exists $w \in \Sigma^*$
		such that $M$ accepts $w\}$.
	\w {\bf{}Problem}: Does $M$ accept some string? Stated otherwise,
		Is $L(M)$ non-empty?
	\w {\sf{}AcceptSomething$_{\mbox{\scriptsize{}TM}}$} 
		is r.e. since we can 
		design a TM $M'$ that perform an infinite {\em{}dovetailing\/} 
		procedure
		on all possile strings $w_1, w_2, \cdots$ of $\Sigma^*$
	\w {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} 
		$\le_m$
		{\sf{}AcceptsSomething$_{\mbox{\scriptsize{}TM}}$} 
		\bit
		\w {\sf{}AcceptSomething$_{\mbox{\scriptsize{}TM}}$} 
			$\le_m$
		{\sf{}Halting$_{\mbox{\scriptsize{}TM}}$}
		\eit
	\eit
\w ({\bf{}The Totality Problem for Turing Machines})
	\bit
	\w {\sf{}AcceptsAll$_{\mbox{\scriptsize{}TM}}$} $=
		\{\arc{M}:$ $M$ is a TM and $M$ halts on all 
		$w \in \Sigma^*\}$.
	\w {\bf{}The Problem}: Does $M$ halt on all inputs?
	\w {\sf{}Halting$_{\mbox{\scriptsize{}TM}}$} 
		$\le_m$
		{\sf{}AcceptsAll$_{\mbox{\scriptsize{}TM}}$} 
	\eit
\w ({\bf{}The Equivalence Problem for Turing Machines})
	\bit
	\w {\sf{}Equiv$_{\mbox{\scriptsize{}TM}}$} $=
		\{\arc{M_1, M_2}:$ $M_1, M_2$ are TMs and $L(M_1) = L(M_2)\}$.
	\w {\bf{}The Problem}: Does $M_1$ and $M_2$ accept the same language?
	\w {\sf{}AcceptsAll$_{\mbox{\scriptsize{}TM}}$} 
		$\le_m$
		{\sf{}Equiv$_{\mbox{\scriptsize{}TM}}$} 
	\eit
\w ({\bf{}The Finiteness Problem})
	\bit
	\w {\sf{}Finite$_{\mbox{\scriptsize{}TM}}$} $=
		\{\arc{M}:$ $M$ is a TM and $L(M)$ is finite$\}$.
	\w {\bf{}The Problem}: Does $M$ accept a finite language?
	\w Provable using {\em{}Rice's Theorem}.
	\eit
\w ({\bf{}The Regularness Problem})
	\bit
	\w {\sf{}Regular$_{\mbox{\scriptsize{}TM}}$} $=
		\{\arc{M}:$ $M$ is a TM and $L(M)$ is regular$\}$.
	\w {\bf{}The Problem}: Does $M$ accept a regular language?
	\w {\sf{}AcceptsAll$_{\mbox{\scriptsize{}TM}}$}
		$\le_m$
		{\sf{}Regular$_{\mbox{\scriptsize{}TM}}$} 
	\w Let $R$ be the decider for 
		{\sf{}Regular$_{\mbox{\scriptsize{}TM}}$}. Now, how can
		we use $R$ to build a decider for \am?
	\w (cont.) Simple! We need only to be modify $M$ into $M'$ such that
		{\em{}$R$ accepts $\arc{M'}$ 
		iff $M$ accepts $w$\/}; i.e. $L(M')$ is regular iff
		$M$ accepts $w$.
	\w (cont.) Design $M'$ to accept the nonregular language
		$\{0^n1^n: n \le 0\}$ if $M$ does not accept $w$ and
		the regular language $\Sigma^*$ if $M$ accepts $w$.
	\w (cont.) $M'$ is defined as: On input $w$,
		\ben
		\w If $w$ has the form $0^n1^n$, {\em{}accept\/};
		\w Otherwise, run $M$ on $w$ and {\em{}accept\/} if
			$M$ accepts $w$.
		\een
		
	\w Also proved using {\em{}Rice's Theorem}.
	\eit
\w ({\bf{}The Context-freeness Problem})
	\bit
	\w {\sf{}ContextFree$_{\mbox{\scriptsize{}TM}}$} $=
		\{\arc{M}:$ $M$ is a TM and $L(M)$ is context-free$\}$.
	\w {\bf{}The Problem}: Does $M$ accept a context-free language?
	\w Provable using {\em{}Rice's Theorem}.
	\eit
\w ({\bf{}The Post Correspondence Problem (PCP)})
	\bit
	\w An instance of the PCP is a collection $P$ of dominos:
	\[ P = \left\{\left[\frac{t_1}{b_1}\right], 
		\left[\frac{t_2}{b_2}\right], \cdots, 
		\left[\frac{t_k}{b_k}\right]\right\},\]
	and a {\em{}match\/} is a sequence $i_1, i_2,\cdots, i_l$ where
	$t_{i_1}t_{i_2}\cdots{}t_{i_l} = b_{i_1}b_{i_2}\cdots{}b_{i_l}$.
	Here, $1 \le i_m \le k$ ($1 \le m \le l$)
	and for every $i_m$ and $i_n$ ($m \ne n$),
	they need not be different positives.
	\w {\sf{}PCP} = $\{\arc{P}: \mbox{\ $P$ is a Post correspondence
		problem with a match}\}$.
	\w {\bf{}Problem}: Given a set of dominos, is there a match?
	\w {\sf{}PCP} is undecidable.
	\w A Proof of the undecidability uses {\em{}reduction from
		\am\ via accepting computation histories}.
	\eit
\eit



\section{The Recursion Theorem}
\subsection{Self-reference}
\def\self{{\em{}SELF\/}}
\bit
\w There's a `computable' function $q: \Sigma^* \rightarrow \Sigma^*$,
	where, for each string $w$, $q(w)$ is the description of
	the Turing machine $P_w$ that prints out $w$ and then halts. That is,
	\[ q(w) = \arc{P_w}.\]
\w Let's design a Turing machine {\em{}SELF} that ignores its input
	and prints out $\arc{\mbox{\em{}SELF\/}}$, 
	a copy of its own description.
	\bit
	\w {\em{}SELF\/} consists of two parts $A$ and $B$.
	\w We want \self\ to print out $\arc{\mbox{\self}} = \arc{AB}$.
	\w {\em{}$A$ prints out a description of $B$, and conversely $B$ prints
		out a description of $A$.\/}
	\w $A$ uses $q(\arc{B})$ to print out $\arc{B}$. That is,
		$A \equiv P_{\langle{}B\rangle}$.
	\w Our description of $A$ depends on having a description of $B$;
		so {\em{}we can't complete the description of $A$ until we
		construct $B$\/}.
	\w We cannot use the same strategy for $B$ since it incurs a
		{\em{}circularity\/}.
	\w {\em{}$B$ computes $A$ from the output that $A$ produces.\/}
	\w {\sl\bfseries{}Since $\arc{A} = q(\arc{B})$,
		if $B$ can obtain $\arc{B}$, it can apply $q$ to that
		and obtain $\arc{A}$.\/}
		\bit
		\w How does $B$ obtain $\arc{B}$? It was left on the tape
			when $A$ finished!
		\eit
	\eit
\eit
\subsection{The recursion theorem}
\bit
\w The recursion theorem extends the technique we used in constructing
	\self\ so that a program can obtain its own description
	and then go on to compute with it, instead of merely 
	printing it out.
\w ({\bf{}Recursion Theorem})\ 
	{\sl\bfseries{}Let $T$ be a Turing machine that computes a function
	$t : \Sigma^* \times\Sigma^* \rightarrow \Sigma^*$.
	There is a Turing machine $R$ that computes a function
	$r: \Sigma^* \rightarrow \Sigma^*$, where for every $w \in \Sigma^*$
	\[r(w) = t(\arc{R}, w).\]}
\eit

\subsection{Applications of the recursion theorem}
\bit
\w ({\bf{}Reification}) 
	When designing a Turing machine $M$, 
	we can include the phrase ``obtain own description $\arc{M}$.''
	\bit
	\w This result is the central theme in the field of
		{\em{}computational reflection\/}.
	\eit
\w If $M$ is a Turing machine, then we say that the {\bf{}length}
	of the description $\arc{M}$ of $M$ is the number of symbols
	in the string describing $M$. Say that $M$ is {\bf{}minimal}
	if there is no Turing machine equivalent to $M$ that has a shorter
	description. Let
	\[ \mbox{\sf{}Minimal$_{\mbox{\scriptsize{}TM}}$} =
		\{\arc{M}: \mbox{\ $M$ is a minimal TM}\}.\]
	\bit
	\w {\sf{}Minimal$_{\mbox{\scriptsize{}TM}}$} is not
		r.e.
	\eit
\eit

\subsection{Fixed Points}
\bit
\w A {\bf{}fixed point} of a `function' is a value that isn't changed
	by application of the function.
\w {\sl\bfseries{}Let $t: \Sigma^* \rightarrow \Sigma^*$ 
	be a computable function.
	Then there is a Turing machine $F$ wherein $t(\arc{F})$
	describes a Turing machine equivalent to $F$.}
\eit

\section{Decidability of Logical Theories}
\bit
\w If ${\cal{}M}$ is a model, we define the {\bf{}theory of ${\cal{}M}$},
	denoted by Th$(\cal{}M)$, be the collection of true sentences
	in the language of that model\footnote{For 
	details of mathematical logic, refer to `Notes on Mathematical
	Logic.'}.
\w Alonzo Church, building on the work of Kurt G\"{o}del, showed
	that {\em{}no algorithm can decide in general whether
	statements in number theory are true or false\/}.
\w Th$(\N, +)$ is decidable.
\w Th$(\N, +, \times)$ is undecidable.
	\bit
	\w Let $M$ be a Turing machine and $w$ a string. 	
		We can construct from $M$ and $w$ a formula
	$\phi_{M, w}$ in the language of Th$(\N, +, \times)$
	that contains a single free variable $x$,
	whereby the sentence $(\exists{x})\left[\phi_{M,w}\right]$ is
	true iff $M$ accepts $w$.
	\eit	
\w The collection of provable statements in Th$(\N, +, \times)$
	is Turing-acceptable (r.e.).
\w Some true statements in Th$(\N, +, \times)$ is not provale.
\w The sentence $\psi_{\mbox{\scriptsize{}unprovable}}$,
	as described in the proof of this theorem, is unprovable.
\eit

\section{Oracles and Turing Reducibility}
\subsection{Oracles}
\bit
\w An {\bf{}oracle} for a language $B$ is an external device that is capable
	of reporting whether any string $w$ is a member of $B$.
\w An {\bf{}oracle Turing machine} is a modified Turing machine that has 
	the additional
	capability of querying an oracle.
	We write $M^B$ to describe an oracle Turing machine
	that has an oracle for language $B$.
\eit
\subsection{Turing reducibility}
\bit
\w Consider an oracle for \am. An oracle Turing machine with an oracle
	for \am\ can decide more languages thatn an ordinary Turing
	machine can. Such a machine can obviously decide \am\ itself, by
	querying the oracle about the input.
	\bit
	\w Sup' that we'd like to decide \etm, with the following
		procedure called 
		$T^{{\mbox{\scriptsize\sf{}Accepts}_{\mbox{\tiny\sf{}TM}}}}$:
	\ben
	\w [$\diamond$.] On input $\arc{M}$, where $M$ is a TM:
	\w Construct the follwing TM $N$:	
		\ben
		\w [($\diamond$)] On any input:
		\w Run $M$ in parallel on all strings in $\Sigma^*$.
		\w If $M$ halts on any of these strings, {\em{}accept\/}.
		\een
	\w Query the oracle to determine whether $\arc{N, 0} \in $\ \am.
	\w If the oracle answers NO, {\em{}accept\/}; if YES, 
		{\em{}reject\/}.
	\een
	
	\w We say that a Turing machine $E$ is {\bf{}decidable relative to}
		$A$
	\eit
\w Language $A$ is {\bf{}Turing reducible} to language $B$, written
	$A \le_T B$, if $A$ is decidable relative to $B$.
\eit


\bibliographystyle{plain}
\bibliography{00bib/mac,00bib/theory,00bib/algo,00bib/pl}
\nocite{Sipser96,HU79,Rogers87,Kleene71,Jones97,FB94}
\nocite{HU79,Sipser96}
\pagebreak
\tableofcontents
\end{document}
