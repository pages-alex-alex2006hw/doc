\documentclass{note}
\usepackage{mydef}
\usepackage[all]{xy}
\begin{document}
\title{\large\bf Problems on Logic Minimization: An Overview}
\author{\normalsize{}Cheoljoo Jeong $\arc{\mbox{cjeong@cs.columbia.edu}}$}
\maketitle

\section{Covering Problems}

\subsection{The vertex cover problem}
\begin{definition}
Given a graph $G = (V, E)$, a vertex cover of $G$ is a subset 
$V' \subseteq V$ such that, for all $(u, v) \in E$, either $u \in V'$
or $v \in V'$.
\end{definition}


\subsection{The set cover problem}
\begin{definition}
An instance $(T, P)$ of the \bb{set cover problem} consists of a 
finite set $T = \{t_1, \cdots, t_m\}$ 
and a collection $P = \{P_1, \cdots, P_n\}$ 
of subsets of $T$, such that
every element of $T$ belongs to at least one subset in $P$, i.e.
$T = \bigcup_{p \in P} p$. 
\end{definition}
We say that a subset $p \in P$ \bb{covers} its elements.
The set cover problem is to 
find a {\em minimum-cardinality\/} subset $C \subseteq P$
whose members cover all of $T$, i.e.
$T = \bigcup_{p \in C} p.$

\paragraph{Complexity results} This problem remains NP-complete 
even if all $p \in P$ have $|p| \leq 3$.
But it is solvable in polynomial time by matching techniques
if all $p \in P$ have $|p| \leq 2$ \cite[page 222]{GJ79}.

\subsection{The weighted set cover problem}
\begin{definition}
An instance of the weighted set cover problem is $(T, P, w)$ where
$w$ is a weight function on the $P$; $T$ and $P$ are defined 
the same as the set cover problem.
The \bb{weighted set cover problem} is to find a {\em minimum-weight}
subset $C \subseteq P$, whose members cover all of $T$, i.e.
to find a cover $C$ of $T$ such that 
$\sum_{p \in C}p\cdot{}w(p)$
is a minimum of any cover.
\end{definition}


\subsection{The hitting set problem}
\begin{definition}
Given a set of subsets $P = \{P_1, \cdots, P_n\}$ of the
set $T = \{t_1, \cdots, t_m\}$, the \bb{hitting set problem} is
to find a smallest subset $T' \subseteq T$ such that each subset
$P_i$ contains at least one element of $T'$.
Thus $T' \cap P_i \ne \emptyset$ for all $1 \le i \le n$.
\end{definition}
Actually, hitting set is \bb{dual} to set cover.
If we replace each element of $T$ by a set of names of the subsets that
contain it,
now $T$ and $P$ have exchanged roles,for we seek a set of subsets from
$T$ to cover all the elements of $S$.


\paragraph{Characteristic vector representation}
An instance of the set cover problem can be represented as
a \bb{characteristic vector} $A$ such that
\[ A_{ij} = \left\{\begin{array}{ll}
  1, & \mbox{if\ } P_i \mbox{\ covers\ } t_j, \\
  0, & \mbox{otherwise}.
  		   \end{array}\right. \]
A characteristic vector is also called a \bb{constraint matrix}
when dealing with logic minimization problems.


\subsection{Reduction to the integer programming problem}
The problem of finding a minimum cover of a set is reduced
to the problem of finding a binary vector $x$ representing a set of
primes with minimum cardinality $|c|$ such that
\[ Ax \ge 1 \]
where $A$ is a $m\times n$ characteristic vector, $x$ is a column
vector of size $n$ and $1$ is the column vector of size $m$ where all the
elements are $1$.
Here, $a_{ij} = 1$ iff $t_i$ is covered by $p_j$.
$x_i = 1$ iff $p_i$ is chosen to be in the cover $C$.
\[ \left[\begin{array}{lll}
	a_{11} & \cdots & a_{1n} \\
	\vdots & \ddots  & \vdots \\
	a_{m1} & \cdots & a_{mn} \\
	 \end{array}\right] \times 
	\left[\begin{array}{l}
	x_1 \\ \vdots \\ x_n
	      \end{array}\right] =
	\left[\begin{array}{l}
	c_1 \\ \vdots \\ c_m
	      \end{array}\right]
\]
Then $c_i$
\[ c_i = \sum_{k=1}^n a_{ik}x_k = a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n\]
represents the number of sets in $C$ which covers $t_i$.
So, for each $c_i$, $i = 1, \cdots, m$, we should have $c_i \le 1$ for $C$
to be a valid cover.



\subsection{Approximation schemes for the set cover problem}
\paragraph{A greedy approach}
Begin by placing the largest $p_i$ into $C$, and then mark all its elements 
as covered. this approach always gives a set cover using at most $\ln n$
as many sets as optimal, and in practice it usually does a lot better.




\section{The Independence Set Problem}
An \bb{independence set} in a graph $G = (V, E)$ is a subset $V' \subseteq V$
such that, for all $u, v \in V'$,  $(u, v) \not\in E$.

\subsection{Relations between problems}
\begin{lemma}
For any graph $G = (V, E)$ and subset $V' \subseteq V$, the following
statements are equivalents \cite{GJ79}:
\ben
\w [(a)] $V'$ is a vertex cover for $G$.
\w [(b)] $V - V'$ is an independent set for $G$.
\w [(c)] $V - V'$ is a clique in the complement $G^c$ of $G$, where $G^c =
  (V, E^c)$ with $E^c = \{(u, v) : u, v \in V \mbox{\ and\ } (u, v) \not\in
E\}$. 
\een
\end{lemma}
Thus, these three problems may be regarded as different versions of one another.



\section{The Logic Minimization Problems}
The logic minimization problem was first presented by Quine
as the problem of finding a minimal equivalent of the given
propositional calculus formula.
Actually, a logic minimization problem is a set covering problem
in disguise.

In the setting of logic minimization problems,  each 
element of $T$ is an ON-set \bb{minterm}
and each element of $P$ is a \bb{prime implicant}. 

\subsection{Unate covering problem}
\begin{definition}
Given a constraint matrix $A$, we can define a \bb{constraint equation}
as follows.
\end{definition}


\begin{definition}
Let $J = \{1, \cdots, n\}$, and let $p = [p_1, \cdots, p_n]$ be a vector
of $n$ Boolean variables. 
Given a subset $J_i \subseteq J$, for $i = 1, \cdots, m$
let $\sigma_i = \sum_{j \in J_i} p_j$.
$\sigma_i$ represents a single multiplicant in a constraint equation.

Then the \bb{unate covering problem} is the problem of 
finding a minimum-cardinality subset $S \subseteq J$, 
such that
	\[ \prod_{i=1}^m {\sigma_i}^S = 1,\]
where 
$\sigma_i^S = \sum_{j \in J_i}[j \in S]$.
Note that $[j \in S]$ is a characteristic function which evaluates
to $1$ if $j \in S$ and evalutes to $0$ otherwise.
%$\sigma_i^S$ is defined by setting $p_k = 1$ where $k \in S$
%and $p_k = 0$ otherwise.
%setting $p_j = 1$, for all $p_j \in S$.
%That is, for any other subset $S'$ having the above properties,
%we have $|S| \le |S'|$. Note each of the sums $\sigma_i(p): \{0, 1\}^n
%\rightarrow \{0, 1\}$ is a Boolean function.
\end{definition}

\begin{definition}
Let $A$ be a matrix of $m$ rows and $n$ columns, for which $A_{ij}$ is
either $0$ or $1$. Then the \bb{unate covering problem} 
is the problem of finding a minimum-cardinality column subset $S$ 
such that 
%for all $S'$,
\[ (\forall i \in \{1, \cdots, m\})(\exists j \in \{1, \cdots, m\})[A_{ij} 
= 1]. \]
%\[ (\exists j \in S')[A_{ij} = 1], \
% (\forall i \in \{1, \cdots, n\})[|S| \le |S'|]. \]
%That is, the columns in the set $S$ cover $M$ in the sense that every
%row of $A$ contains a $1$-entry in at least one of the columns of $S$,
%and there is no smaller set $S'$ which also covers $M$.
\end{definition}


\subsection{Constraint Matrix Reduction}
\begin{definition}
\bb{The Covering Problem (Set Cover Problem)}\ 
Given a finite set $M = \{m_1, m_2, \cdots, m_n\}$ and 
a family ${\cal P} \subseteq 2^M$, 
find a smallest set $S \subseteq {\cal P}$ such that
	$\bigcup_{s \in S} s = M$.
\end{definition}

\paragraph{Reduction from the Boolean logic minimization problem}
If we let $M$ be the set of minterms and $\cal P$ be the set of prime
implicants, a Boolean logic minimization problem instance is reduced
into a covering problem instance.


\paragraph{Tabular represenation of the problem}
We can represent the covering problem as in the following table $T$:
\begin{quote}
\centerline{\begin{tabular}{c|cccc}
& $p_1$ & $p_2$ & $\cdots$ & $p_k$ \\ \hline
$m_1$ & 0 & 1 & $\cdots$ & 1\\
$m_2$ & 1 & 0 & $\cdots$ & 0\\
$\vdots$ & $\vdots$ & $\vdots$ & & $\vdots$ \\
$m_n$ & 1 & 0 & $\cdots$ & 1\\
\end{tabular}}
\end{quote}
where $T(m_i, p_j) = 1$ if and only if $p_j$ covers $m_i$, i.e.
$m_i \in p_j$.

\paragraph{Solution space}
The solution space for the problem instance $(M, {\cal P})$ is 
${\cal S} = 2^{\cal{}P}$,
where the space can be partitioned into those of
{\em feasible\/} solutions and {\em infeasible\/} solutions.
Again, the space of feasible solutions can be further partitioned
into the space of {\em optimal\/} solutions and the space of {\em suboptimal\/}
solutions.


\paragraph{Row dominance and column dominance}
For background, see the handout.
We can eliminate the dominated column with the guarantee that
this elimination would not compromise the optimality of the algorithm.
Suppose that $p_i$ dominates $p_j$, i.e., for every $m \in p_j$, 
$m \in p_i$.
If there exists an optimal solution involving $p_j$,
we can replace $p_j$ with $p_i$ and still have an optimal solution.

But note that there might exist optimal solutions
which contain $p_j$.
Suppose that a partition $\{p_j, p_k\}$  of $M$
is an optimal solution.
Even though alternative optimal solution $\{p_i, p_k\}$ could have been 
found by the algorithm, this algorithm eliminates the possiblity
of choosing $\{p_j, p_k\}$ as a solution by eliminating dominated columns.
This amounts to reducing 
the space of optimal solutions in the space exploration by discarding
a portion of the space.


As for row dominance, the validness of this table reduction is based
on the following observation.
Suppose that $m_i$-row is dominated by $m_j$-row, where
$m_i$-row indicates the list of $p$'s which contain $m_i$.
If $P_j = \{p_r\}$ is the set of $p$'s that
contain $m_j$, {\em at least one\/} of this set needed
to get a feasible solution.
So, even though we elminate $m_j$-row, we are still able to 
consider $m_i$-row at a later stage of the algorithm and
our final solution must contain at least one $p$ of $m_i$-row, and thus
a $p$ of $m_j$-row, since $P_i \subseteq P_j$.

This reduction also does not compromise the optimality of the 
algorithm. 
%Since the $m_i$-row should be covered anyhow, so at least 
%one $p$ from the $P_i$ should be selected to be a feasible solution.
Unlike dominated column elimination, no $p$'s are removed from
the table, and $P_j - P_i$ still have a chance to be selected 
in the solution.

And elimination of dominating rows also has a possibility of
leaving out possible optimal solutions, as seen in the 
following example.
Since dominating row elimination can cause a new opportunity
for a dominated column elimination and a dominated column elimination
has a possibility of leaving out possible optimal solutions, 
so does a dominated row elimination.
%\vspace*{4cm}





\paragraph{Relationship between row/column/essential eliminations}
The Quine-McCluskey method iterates prime implicant table reduction step
until it reaches a fixed point, where each reduction step consists of
three substeps: essential elimination, dominated-column elimination, 
and dominating-row elimination.
There's an interrelationship between substeps such that one step may
cause new opportunities for another step.

\[\xymatrix@-0.3pc{
& \txt<5pc>{Essential elimination} \ar@/^3ex/@{<-}[rdd] \ar@/_3ex/[rdd]\\ \\
\txt<7pc>{Dominating row elimination} \ar@/^3ex/[rr]& & 
	\txt<7pc>{Dominated column elimination} \ar@/^3ex/[ll]
}\]


\subparagraph{When a dominated column is eliminated}
A new need for row elimination may arise as seen in the following example:
\begin{quote}
\centerline{\begin{tabular}{l|lll}
 & $p_1$ & $p_2$ & $p_3$  \\ \hline
$m_1$ & X & X &   \\
$m_2$ & X &  & X  \\
\end{tabular}}
\end{quote}
Though $m_1$-row and $m_2$-row are not dominated by each other above, after
eliminating $p_3$-column, $m_1$-row dominates $m_2$-row.
Let's define a {\em row-critical entry\/} to be an entry of the table whose
removal creates a new row dominance. For example, $T(m_1, p_2)$ 
is a row-critical entry here.
If column row with a row-critical entry is removed, a new column dominance
is formed.

And column elmination also creates new essentials.
In the above table, when  we eliminate $p_1$-column, 
then $m_2$ is an essential now.




\subparagraph{When a dominating row is eliminated}
When a row is elminated, a new column dominance may be formed as
in the following table.
\begin{quote}
\centerline{\begin{tabular}{l|ll}
 & $p_1$ & $p_2$ \\ \hline
$m_1$ & X & X   \\
$m_2$ &  &  X   \\
$m_3$ & X &  
\end{tabular}}
\end{quote}
When $m_2$-row is eliminated, $p_1$ dominates $p_2$ and $p_2$ can be
eliminated.
Let's define a {\em column-critical entry\/} to be an entry of the 
table whose removal creates a new column dominance. 
For example, $T(m_2, p_2)$ 
is a column-critical entry in the above example.
If a row with a column-critical entry is removed, a new row dominance
is formed.

But dominating-row elimination does not make a new essential
since, after row elmination, there's no change in $P_j$ for
each $m_i$.

\subparagraph{When an essential is removed}
Though essential removal entails both column elmination and row elmination,
it is not true that these leads to a row dominance.
Consider the following example again:
\begin{quote}
\centerline{\begin{tabular}{l|lll}
 & $p_1$ & $p_2$ & $p_3$  \\ \hline
$m_1$ & X & X &   \\
$m_2$ & X &  & X  \\
$m_3$ &  &  & X 
\end{tabular}}
\end{quote}
When $p_3$ is removed as an essential, we also remove $m_2$-row!
So, no new row dominace is formed after an essential elimination, since
every time a  row-critical column is removed, associated row is also
eliminated.


But column dominance may result from essential elmination
as in the following example.
\begin{quote}
\centerline{\begin{tabular}{l|lll}
 & $p_1$ & $p_2$ & $p_3$ \\ \hline
$m_1$ & X & X &   \\
$m_2$ &  &  & X  \\
$m_3$ &  & X & X  \\
$m_3$ & X &     \\
\end{tabular}}
\end{quote}
Here $p_3$ is an essential and $p_3$ removal entails elmination
of $m_3$-row which contains a column-critical entry $T(m_3, p_2)$.







\subsection{Computation of lower bounds}
Given a constraint matrix $A$, suppose that two rows $t_i$ and 
$t_j$ have nonzero entries in sets 
$R_i = \{k \mid M_{ik} \ne 0\}$ and
$R_j = \{k \mid M_{jk} \ne 0\}$.
$R_i$, which we say the \bb{covering set for row $i$}, 
is simply a set of indices of the columns that cover the
row $i$.
If $R_i \cap R_j = \emptyset$, i.e. if $t_i$ and $t_j$ have
no nonzero columns in common, we say these two rows
are \bb{independent}. 
If $t_i$ and $t_j$ are independent, there exists no single column
that covers both $t_i$ and $t_j$. So, we need at least two
columns to cover $t_i$ and $t_j$.
An \bb{independent set} of a constraint matrix $A$ is a set
of rows such that the rows are pairwise independent.
In other words, covering sets of the rows in an indepedent set are 
pairwise disjoint.

The notion of independent sets provides a good lower bound
on the size of the minimal set cover, since no minimal set cover
can have size smaller than that of the independent set.
If we could find a larger independent set, we can get a tighter
lower bound on the size of the minimal set cover.




\bibliographystyle{plain}
\bibliography{00bib/mac,00bib/algo,00bib/theory,00bib/async}
\nocite{Hochbaum97a,Rudell89,HS96}
\pagebreak
\tableofcontents
\end{document}
