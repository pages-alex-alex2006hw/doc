\documentclass{myproc}
\usepackage{mathptm,mydef,myenv}
%\usepackage{MinionPro}
\begin{document}
\small
\noindent{\large\bf{}Xeon Phi Performance Optimization}

\tableofcontents

\section{Scalability}

\section{Workload Balance}

\section{Barriers}

\section{False Sharing}

\section{Vectorization}
\subsection{Overview}
\bit
\w vectorization of a loop: executing more than one consecutive iterations at
the same time
  \bit
  \w SSE (streaming SIMD extension): usually 2 or 4 iterations
  \eit
\w 512B vector registers
\eit

\subsection{Vectorizable loops}
\bit
\w innermost loop (use openmp for outer loops)
\w loop body must be straight-line code (a single basic block w/ single entry
single exit); not jumps, branches but \bb{masked assignments} are allowed
\w loop must be countable (doesn't have to be statically known; as long as the
number of iterations are known before the loop starts to execute, it's ok)
\w no backward loop-carried dependencies (inter-iteration dependency); forward
dependece is be ok e.g. as shown in
  \begin{verbatim}  
  // VECTORIZABLE
  for (i = 0; i < MAX; ++i) {
    a[i] = b[i] + c[i];
    //a[i-1] always computed before it's used
    d[i] = e[i] + a[i-1];
  }
  \end{verbatim}
   
\eit

\subsection{Vectorizable loops with \#pragma simd}
\subsection{Array notation}
\subsection{Elemental functions}

\subsection{Directives and pragmas}

\section{Memory and cache}
\subsection{Addressing}
\bit
\w Code runs best when data are accessed in sequential address-order from
memory. In many cases, data structure transformation from AoS (array of
structures) to SoA (structure of arrays) is
needed for this. 
  \begin{verbatim}
  // AoS                  // SoA
  typedef struct {        typedef struct {
    int data1;              int data1[100];
    int data2;              int data1[100];
    ...                     ...
  } struct_t;             } struct_t;
  struct_t AoS[100];      struct_t SoA;
  \end{verbatim}
\w Consider accessing \verb+data1+ and \verb+data2+ in a loop:
  \begin{verbatim}
  for (...) {             for (...) {
    ... AoS[i].data1;       ... SoA.data1[i];
  }                       }
  \end{verbatim}
\w Note that there are many fields in \verb+AoS+ (e.g. \verb+data1+ through
\verb+data100+), the distance between \verb+AoS[0].data1+ and
\verb+AoS[1].data1+ is at least 100 integers apart. We cannot exploit the
cache in this case.
\w However, consider the following case:
  \begin{verbatim}
  for (...) {             for (...) {
    ... AoS[i].data1;       ... SoA.data1[i];
    ... AoS[i].data2;       ... SoA.data2[i];
    ...                     ...
    ... AoS[i].data100;     ... SoA.data100[i];
  }                       }
  \end{verbatim}
  Check which of AoS and SoA would be better.
\eit

\subsection{Prefetching}
\bit
\w Consider:
  \begin{verbatim}
  for (...) {
    s = data1[i];
    t = data2[i];
    ...
    ... = s + t; 
  }
  \end{verbatim}
\w The instruction for \verb|s + t| has to wait inside the pipeline until
\verb+data1+ and \verb+data2+ values are read in.
\w Intel compiler performs prefetching but users can give pragmas/directives
or use intrinsic commands to specify it (if statically calculable).
\w Prefetches typically should be for a {\em future iteration of the loop\/},
not the current iteration of the loop. 
\eit

\subsection{Blocking}

\subsection{Tiling}

\subsection{Bandwidth}

\section{Vtune Profiling}


\subsection{CPI}
\bit
\w \bb{CPU\_CLK\_UNHALTED}: the nuber of cycles (clock ticks) executed by the
\bb{core} 
\w \bb{INSTRUCTION\_EXECUTED}: the number of instructions executed by the
\bb{thread} 
\w \bb{Average CPI per thread}: 
 \[
 \frac{\mbox{{\bf{}CPU\_CLK\_UNHALTED}}}{\mbox{\bf{}INSTRUCTIONS\_EXECUTED}} \]
  \bit
  \w how many clocks are required to retire one instruction in one thread
  \eit
\w \bb{Average CPI per core}: 
 \[ \frac{\mbox{{\bf{}CPI per thread}}}{\mbox{\bf{}Number of HW threads
     used}} \]  
  \bit
  \w 
  \eit
\w average CPI per thread $> 4.0$: needs invetigation
\w average CPI per core $> 1.0$: needs invetigation
\eit

\subsection{Vectorization intensity}
\bit
\w defined as 
 \[ \frac{\mbox{{\bf{}VPU\_ELEMENTS\_ACTIVE}}}{\mbox{\bf{}VPU\_INSTRUCTIONS\_EXECUTED}} \]
meaning how many VPU elements are active per VPU instruction
\eit


\end{document}

% LocalWords:  GPU vertices SPMD GPUs
